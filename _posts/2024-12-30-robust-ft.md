---
layout: distill
tags: llm sft data_preprocessing
title: "SFT 데이터셋의 노이즈를 줄여보자"
description: 데이터 디노이징 프레임워크 RobustFT
date: 2024-12-30
giscus_comments: true
related_posts: false
toc:
  beginning: true
---

Downstream task 를 위한 LLM 모델을 학습할 때, 파인튜닝(=SFT) 데이터에 노이즈가 있는 경우, 모델의 성능이 저하된다.

이 논문에서는 RobustFT 라는 프레임워크를 제안하여, 데이터에 노이즈가 있는지 여부를 탐지하고, 노이즈가 있는 경우 재레이블링을 수행하여 모델의 성능을 향상시킨다.

## 노이즈 탐지 (noise identification)

여기서 말하는 데이터에 포함된 "노이즈"란, 여러 LLM 의 응답이 일관성이 없는 경우를 말한다. 즉, prompt 와 response 가 주어졌을 때, 여러 LLM 의 응답이 일관성이 없는 경우 노이즈가 있다고 판단한다.

### Methods

여러 전문가 LLMs 과 Checker 메커니즘을 사용하여 데이터의 노이즈를 식별한다.

1. 어떤 base LLM 을 사용하여 정답 $y$ 가 있는 query $q_i$ 에 대해 응답 $\hat{y}_i$ 를 생성하는 것을 생각해보자.
2. LLM 으로 (1) step-by-step reasoning (2) reflection 을 계속 반복하면서 응답 $\hat{y}^{reas}_i$ 를 생성하도록 한다.
3. Checker 는 지금까지의 응답들 ($y,\hat{y}_i, \hat{y}^{reas}_i$) 을 이용해서 노이즈가 있는지 여부를 판단한다.
4. Checker 는 응답의 일관성 정도를 0 또는 1 의 값으로 판단하는데, 0 이면 노이즈가 있는 것이고 1 이면 노이즈가 없는 것이다.

여기서 Checker 메커니즘은 상당히 naive 한데, 데이터셋마다 메커니즘이 다르다. 
예를 들어, MMLU 같은 경우는 응답들의 정답을 추출해서 서로 같은지 비교하는 것으로 노이즈 여부를 판단한다.

### 참고

실험에서 LLM 으로 Gemma2-9B, Llama3.1-8B 를 사용하였다.



## 노이즈 제거 (de-noising)

1. Review Agent: context-enhanced reasoning with clean samples to store label noisy instances
2. a perplexity-based data selection mechanism to exclude samples with low confidence scores


## 느낀점

정답(또는 golden reference) 이 없는 경우 Checker 가 잘 작동하지 않을것 같다.

데이터 정제하는 건 좋은데, 다수의 LLM 이용해서 정제하는 비용은 또 다른 얘기다.

## References

RobustFT: Robust Supervised Fine-tuning for Large Language Models under Noisy Response

- paper: https://huggingface.co/papers/2412.14922
- code: https://github.com/luo-junyu/RobustFT