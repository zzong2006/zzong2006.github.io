<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://zzong2006.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://zzong2006.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-01-04T07:47:19+00:00</updated><id>https://zzong2006.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">RAG Competition</title><link href="https://zzong2006.github.io/blog/2025/rag-competition/" rel="alternate" type="text/html" title="RAG Competition"/><published>2025-01-04T00:00:00+00:00</published><updated>2025-01-04T00:00:00+00:00</updated><id>https://zzong2006.github.io/blog/2025/rag-competition</id><content type="html" xml:base="https://zzong2006.github.io/blog/2025/rag-competition/"><![CDATA[<p>RAG ê´€ë ¨ ëŒ€íšŒ ëª©ë¡ì„ ì •ë¦¬í•´ë³´ë ¤ í•œë‹¤.</p> <hr/> <h3 id="1-financerag-challenge-at-icaif-24-ì¢…ë£Œ">1. FinanceRAG Challenge at ICAIF â€˜24 (ì¢…ë£Œ)</h3> <p>5th ACM International Conference on AI in Finance (ICAIFâ€™24)ì—ì„œ RAG ê´€ë ¨ ê²½ì§„ëŒ€íšŒë¥¼ ê°œìµœí–ˆìŠµë‹ˆë‹¤.</p> <p>ìµœê·¼ ê¸ˆìœµê¶Œì—ì„œë„ LLM ì‚¬ìš©ì— ëŒ€í•´ ë§¤ìš° ë§ì€ ê´€ì‹¬ë“¤ì„ ê°–ê³  ê³„ì‹œê³ , ë³´ë‹¤ ì •êµí•œ ì‚¬ìš©ì„ ìœ„í•´ RAGì´ ë§ì€ ì£¼ëª©ì„ ë°›ê³  ìˆìŠµë‹ˆë‹¤.</p> <p>ì´ë²ˆ ê²½ì§„ëŒ€íšŒëŠ” ì°¸ê°€ìë“¤ì´ ì§ì ‘ RAG ì‹œìŠ¤í…œì„ êµ¬í˜„í•´ë³¼ ìˆ˜ ìˆë„ë¡ ì¤€ë¹„ í•˜ì˜€ìŠµë‹ˆë‹¤. Linqì—ì„œ ì§ì ‘ ë¯¸êµ­ì˜ ì¦ê¶Œì‹œì¥ ê³µì‹œ, ë¦¬í¬íŠ¸ ë“±ì„ ë°”íƒ•ìœ¼ë¡œ query-corpus datasetì„ ì„¸ì‹¬í•˜ê²Œ ì¤€ë¹„í•´ì£¼ì…¨ìŠµë‹ˆë‹¤. íŠ¹íˆ ê¸ˆìœµë¶„ì•¼ì—ëŠ” ì´ëŸ¬í•œ ë°ì´í„°ì…‹ì´ ì—†ëŠ”ë°ìš”, ì°¸ê°€ìë“¤ì´ ë§¤ìš° ì¢‹ì€ ë°ì´í„°ì…‹ì„ ë°”íƒ•ìœ¼ë¡œ RAG ì‹œìŠ¤í…œì„ êµ¬í˜„í•´ë³´ê³  evaluationë„ í•´ë³¼ ìˆ˜ ìˆëŠ” ë§¤ìš° ì¢‹ì€ ê¸°íšŒë¼ê³  ìƒê°í•©ë‹ˆë‹¤.</p> <p>https://www.kaggle.com/competitions/icaif-24-finance-rag-challenge/overview</p> <h3 id="2-dacon-ì¬ì •ì •ë³´-ai-ê²€ìƒ‰-ì•Œê³ ë¦¬ì¦˜-ê²½ì§„ëŒ€íšŒ-ì¢…ë£Œ">2. Dacon: <a href="https://dacon.io/competitions/official/236295/overview/description">ì¬ì •ì •ë³´ AI ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ ê²½ì§„ëŒ€íšŒ</a> (ì¢…ë£Œ)</h3> <p>ëŒ€íšŒ ê¸°ê°„: 2024ë…„ 7ì›” 29ì¼ ~ 2024ë…„ 8ì›” 23ì¼</p> <p>íŠ¹ì´í•œì ì€ RAG ë¡œ í™œìš©í•  ë°ì´í„°ë¥¼ PDF í˜•íƒœë¡œ ì œê³µí•œë‹¤ëŠ” ì ì´ë‹¤.</p> <p>ë¬¼ë¡  LLM í•™ìŠµì— í•„ìš”í•œ Question-Answer pair ì—­ì‹œ ì œê³µëœë‹¤.</p> <p>ëŒ€ë¶€ë¶„ e5 ëª¨ë¸ë¡œ vector search ë¥¼ ìœ„í•œ ì„ë² ë”©ì„ ì§„í–‰í•˜ì˜€ë‹¤.</p> <p>í•œ ìš°ìŠ¹íŒ€ì—ì„œëŠ” YOLOv10 ê¸°ë°˜ Document Layout Analysisë¥¼ í†µí•´ PDF parserë¥¼ êµ¬í˜„í•˜ì˜€ë‹¤ê³  í•œë‹¤.</p> <h3 id="3-aicrowd-crag-comprehensive-rag-benchmark-ì¢…ë£Œ">3. AiCrowd: <a href="https://www.aicrowd.com/challenges/meta-comprehensive-rag-benchmark-kdd-cup-2024">CRAG: Comprehensive RAG Benchmark</a> (ì¢…ë£Œ)</h3> <p>ëŒ€íšŒ ê¸°ê°„: 2024ë…„ 5ì›” 20ì¼ ~ 2025ë…„ 1ì›” 25ì¼</p>]]></content><author><name></name></author><category term="RAG"/><category term="Competition"/><summary type="html"><![CDATA[RAG ê´€ë ¨ ëŒ€íšŒ ëª©ë¡ì„ ì •ë¦¬í•´ë³´ë ¤ í•œë‹¤.]]></summary></entry><entry><title type="html">í–‰ë ¬ ë¯¸ë¶„ ê¸°ì´ˆ (with Trace)</title><link href="https://zzong2006.github.io/blog/2025/matrix-derivative/" rel="alternate" type="text/html" title="í–‰ë ¬ ë¯¸ë¶„ ê¸°ì´ˆ (with Trace)"/><published>2025-01-03T00:00:00+00:00</published><updated>2025-01-03T00:00:00+00:00</updated><id>https://zzong2006.github.io/blog/2025/matrix-derivative</id><content type="html" xml:base="https://zzong2006.github.io/blog/2025/matrix-derivative/"><![CDATA[<p>í–‰ë ¬ì˜ ëŒ€ê° ì„±ë¶„ì˜ í•©ì¸ Trace ($ \text{Tr} $) ê°€ í¬í•¨ëœ í–‰ë ¬ ë¯¸ë¶„ ê·œì¹™ì— ëŒ€í•´ ì •ë¦¬í•´ë³´ë ¤ í•œë‹¤.</p> <hr/> <h2 id="ê·œì¹™-1--fracpartialpartial-w_d-texttra-w_d--atop-">ê·œì¹™ 1: $ \frac{\partial}{\partial W_d} \text{Tr}(A W_d) = A^\top $</h2> <p>ì—¬ê¸°ì„œ $ A $ëŠ” $ m \times n $ í–‰ë ¬ì´ê³  $ W_d $ëŠ” $ n \times m $ í–‰ë ¬ì´ë¼ê³  ê°€ì •í•œë‹¤.</p> <p>í–‰ë ¬ ë¯¸ë¶„ì˜ ê²°ê³¼ëŠ” ë¯¸ë¶„í•œ í–‰ë ¬ì˜ í¬ê¸°ë¥¼ ë”°ë¼ì•¼ í•˜ë¯€ë¡œ, ì´ë¥¼ ë§ì¶”ê¸° ìœ„í•´ì„œ transpose ë¥¼ ì·¨í•œë‹¤ê³  ìƒê°í•˜ë©´ í¸í•˜ë‹¤.</p> <p>(ì°¸ê³ ) Trace ëŠ” ì •ì‚¬ê°í–‰ë ¬ì— ëŒ€í•´ì„œë§Œ ì •ì˜ëœë‹¤.</p> <h3 id="ì˜ˆì‹œ">ì˜ˆì‹œ</h3> <p>ê°„ë‹¨í•œ ì˜ˆì‹œë¥¼ ë“¤ì–´ë³´ì.</p> \[A = \begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \\ \end{bmatrix}, \quad W_d = \begin{bmatrix} x &amp; y \\ z &amp; w \\ \end{bmatrix}\] <p>$ \text{Tr}(A W_d) $ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°ëœë‹¤.</p> \[\text{Tr}(A W_d) = \text{Tr}\left( \begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \\ \end{bmatrix} \begin{bmatrix} x &amp; y \\ z &amp; w \\ \end{bmatrix} \right) \\[10pt] = \text{Tr}\left( \begin{bmatrix} 1x + 2z &amp; 1y + 2w \\ 3x + 4z &amp; 3y + 4w \\ \end{bmatrix} \right) \\[10pt] = (1x + 2z) + (3y + 4w)\] <p>ì´ì œ $ W_d $ ì˜ ê° ì›ì†Œì— ëŒ€í•´ í¸ë¯¸ë¶„ì„ ê³„ì‚°í•´ë³´ì.</p> <ul> <li>$ \frac{\partial}{\partial x} \text{Tr}(A W_d) = 1 $</li> <li>$ \frac{\partial}{\partial y} \text{Tr}(A W_d) = 3 $</li> <li>$ \frac{\partial}{\partial z} \text{Tr}(A W_d) = 2 $</li> <li>$ \frac{\partial}{\partial w} \text{Tr}(A W_d) = 4 $</li> </ul> <p>Trace ì—°ì‚°ì€ ìŠ¤ì¹¼ë¼ ê°’ìœ¼ë¡œ ê³„ì‚°ë˜ì§€ë§Œ, ì´ë¥¼ í–‰ë ¬ $ W_d $ ì˜ ì›ì†Œ ê°ê°ì— ëŒ€í•´ í¸ë¯¸ë¶„í•˜ë©´, ì›ì†Œë³„ ë³€í™”ìœ¨ì„ í¬í•¨í•œ ê²°ê³¼ê°€ í–‰ë ¬ í˜•íƒœë¡œ ë‚˜íƒ€ë‚œë‹¤. ê·¸ ê²°ê³¼, ì•„ë˜ì™€ ê°™ì´ transpose ëœ Aê°€ ë‚˜ì˜¨ë‹¤.</p> \[\frac{\partial}{\partial W_d} \text{Tr}(A W_d) = A^\top = \begin{bmatrix} 1 &amp; 3 \\ 2 &amp; 4 \\ \end{bmatrix}\]]]></content><author><name></name></author><category term="matrix"/><category term="calculus"/><summary type="html"><![CDATA[í–‰ë ¬ì˜ ëŒ€ê° ì„±ë¶„ì˜ í•©ì¸ Trace ($ \text{Tr} $) ê°€ í¬í•¨ëœ í–‰ë ¬ ë¯¸ë¶„ ê·œì¹™ì— ëŒ€í•´ ì •ë¦¬í•´ë³´ë ¤ í•œë‹¤.]]></summary></entry><entry><title type="html">Semantic Retrieval at Walmart</title><link href="https://zzong2006.github.io/blog/2025/semantic-retrieval-at-walmart/" rel="alternate" type="text/html" title="Semantic Retrieval at Walmart"/><published>2025-01-03T00:00:00+00:00</published><updated>2025-01-03T00:00:00+00:00</updated><id>https://zzong2006.github.io/blog/2025/semantic-retrieval-at-walmart</id><content type="html" xml:base="https://zzong2006.github.io/blog/2025/semantic-retrieval-at-walmart/"><![CDATA[<h2 id="proposed-method">Proposed Method</h2> <ol> <li>a hybrid system for e-commerce search deployed at Walmart that combines traditional inverted index and embedding-based neural retrieval to better answer user tail queries.</li> <li>a novel method of selecting negative examples for training a large neural retrieval model and an approximate metric to evaluate the performance</li> </ol> <h2 id="prudction-search-vs-web-search">Prudction search vs. Web search</h2> <p>Production search is way more challenging than web search.</p> <ul> <li>Product titles (the main search-able text) are generally much shorter than web documents.</li> <li>While many web documents may contain the same information, a specific product from a seller rarely has a duplicate.</li> </ul> <h2 id="traditional-solutions">Traditional Solutions</h2> <ul> <li>knowledge graph: need a huge amount of domain expertise, and the cost of maintaining these components is high, since the catalog and product vocabulary frequently change in e-commerce</li> <li>BM25, an inverted index: suffers from vocabulary mismatch between the query and the product title</li> <li>neural systems: limited by the fact that the embedding size cannot be too large due to latency concerns</li> </ul> <h2 id="a-hybrid-architecture">A hybrid architecture</h2> <p>â€¦</p> <h2 id="lesson-learned">Lesson Learned</h2> <h3 id="cosine-similarity-vs-inner-product">Cosine similarity vs. Inner product</h3> <ul> <li>inner product is more stable during training and does not require the temperature factor ğœ</li> <li>But, inner product was much harder to optimize when creating the ANN index, compared to cosine similarity.</li> </ul> <h3 id="text-fields">Text fields</h3> <p>Many text fields are generally available for each product, and the quality of the text fields varies. But, we could not extract any boost in performance by using these text fields. This is probably because descriptions can contain a lot of irrelevant text that simply adds noise.</p> <h3 id="model-complexity">Model Complexity</h3> <p>A very deep model or very large embedding size is not necessary to achieve top performance. This is probably because queries and product titles are not very complex from a semantic perspective.</p> <h2 id="abstract">Abstract</h2> <p>In product search, the retrieval of candidate products before re-ranking is more critical and challenging than other search like web search, especially for tail queries, which have a complex and specific search intent. In this paper, we present a hybrid system for e-commerce search deployed at Walmart that combines traditional inverted index and embedding-based neural retrieval to better answer user tail queries. Our system significantly improved the relevance of the search engine, measured by both offline and online evaluations. The improvements were achieved through a combination of different approaches. We present a new technique to train the neural model at scale. and describe how the system was deployed in production with little impact on response time. We highlight multiple learnings and practical tricks that were used in the deployment of this system.</p> <h2 id="references">References</h2> <p>Papers</p> <ul> <li>[1] <a href="https://arxiv.org/pdf/2412.04637">Semantic Retrieval at Walmart</a></li> </ul>]]></content><author><name></name></author><category term="Walmart"/><category term="ANN"/><category term="RAG"/><summary type="html"><![CDATA[Proposed Method]]></summary></entry><entry><title type="html">Text Embedding ëª¨ë¸: E5</title><link href="https://zzong2006.github.io/blog/2025/e5/" rel="alternate" type="text/html" title="Text Embedding ëª¨ë¸: E5"/><published>2025-01-02T00:00:00+00:00</published><updated>2025-01-02T00:00:00+00:00</updated><id>https://zzong2006.github.io/blog/2025/e5</id><content type="html" xml:base="https://zzong2006.github.io/blog/2025/e5/"><![CDATA[<h1 id="original-e5">Original E5</h1> <h2 id="introduction">Introduction</h2> <p>ê¸°ì¡´ì˜ BERT ì™€ GPT ê°™ì€ ëª¨ë¸ì„ ì´ìš©í•´ (ì¶”ê°€ í•™ìŠµ ì—†ì´) text representation ì„ ì¶”ì¶œí•  ìˆ˜ ìˆìœ¼ë‚˜, ì´ëŸ¬í•œ ëª¨ë¸ë“¤ì€ contrastive learning ìœ¼ë¡œ í•™ìŠµì„ ì§„í–‰í•˜ì§€ ì•Šë‹¤ë³´ë‹ˆ embedding í’ˆì§ˆì´ ìƒëŒ€ì ìœ¼ë¡œ ì•„ì‰¬ìš¸ ìˆ˜ ìˆë‹¤.</p> <p>a pre-trained Transformer encoder and average pooling over the output layer to get fixed-size text embeddings</p> <p>two prefix identifiers â€œquery:â€ and â€œpassage:â€ to $q$ and $d$</p> <h2 id="datasets-ccpairs">Datasets: CCPairs</h2> <p>1.3B unfiltered</p> <p>pair (query, passage) ì˜ˆì‹œ</p> <ul> <li>reddit: (post, comment)</li> <li>stackoverflow: (question, upvoted answer)</li> <li>wikipedia: (title, abstract)</li> </ul> <h3 id="a-consistency-based-data-filtering-technique">A consistency-based data filtering technique</h3> <p>ì‹ ê²½ë§ ëª¨ë¸ì´ clean label ì„ ë¨¼ì € í•™ìŠµí•˜ê³  ê·¸ ì´í›„ì— noisy label ì„ í•™ìŠµí•˜ëŠ” ê²½í–¥ì´ ìˆìœ¼ë¯€ë¡œ, ì´ëŸ¬í•œ ê²½í–¥ì„ í™œìš©í•˜ì—¬ ì¼ê´€ì„± ê¸°ë°˜ ë°ì´í„°ì…‹ í•„í„°ë§ ê¸°ë²•ì„ ì ìš©</p> <p>ì•„ë˜ì˜ ë°©ë²•ì„ í†µí•´ 1.3B text pairs ë¥¼ 270M ê°œë¡œ ì¤„ì„</p> <ol> <li>ìš°ì„  1.3B ë°ì´í„°ì…‹ì„ ì´ìš©í•´ì„œ ëª¨ë¸ì„ í•™ìŠµ</li> <li>í•™ìŠµëœ ëª¨ë¸ì„ ì´ìš©í•´ query ì™€ (ì •ë‹µì´ í¬í•¨ëœ) 1M random passages ì— ëŒ€í•œ ì—°ê´€ì„±ì„ ë­í‚¹</li> <li>Top-k(=2) ê°œì˜ passage ì•ˆì— ì‹¤ì œ ì •ë‹µì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸</li> <li>ë§Œì•½ ì •ë‹µì´ í¬í•¨ë˜ë©´ pair ë¥¼ keep, ê·¸ë ‡ì§€ ì•Šë‹¤ë©´ discard</li> </ol> <h2 id="training">Training</h2> <h3 id="contrastive-loss-for-pre-training">Contrastive loss (for pre-training)</h3> <p>ì•„ë˜ì™€ ê°™ì€ InfoNCE contrastive loss ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ</p> \[\min L_{\mathrm{cont}}=-\frac{1}{n} \sum_i \log \frac{\mathrm{e}^{s_\theta\left(q_i, p_i\right)}}{\mathrm{e}^{s_\theta\left(q_i, p_i\right)}+\sum_j \mathrm{e}^{s_\theta\left(q_i, p_{i j}^{-}\right)}}\] <ul> <li>$s_\theta$: ëª¨ë¸ íŒŒë¼ë¯¸í„° $\theta$ ì— ê¸°ë°˜í•œ ìœ ì‚¬ë„ ê³„ì‚° í•¨ìˆ˜</li> <li>$q_i$: query</li> <li>$p_i$: a positive passage</li> <li>$p_{i j}^{-}$: negative passages</li> </ul> <p>ì‹¤ì œ êµ¬í˜„ì€ sentence-transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í–ˆëŠ”ë°, ì°¾ì•„ë³¸ ê²°ê³¼ <a href="https://github.com/UKPLab/sentence-transformers/blob/master/sentence_transformers/losses/MultipleNegativesRankingLoss.py#L13-L125">MultipleNegativesRankingLoss</a> ë¥¼ ì´ìš©í•˜ì—¬ í•™ìŠµí•œ ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤.</p> <h3 id="knowledge-distillation-for-finetuning">Knowledge distillation (for finetuning)</h3> <p>knowledge distillation from a cross-encoder (CE) teacher model</p> <p>KL divergence $D_{\mathrm{KL}}$ for distilling soft labels from the teacher model</p> \[\min D_{\mathrm{KL}}\left(p_{\mathrm{ce}}, p_{\mathrm{stu}}\right)+\alpha L_{\mathrm{cont}}\] <ul> <li>$p_{\mathrm{ce}}$, $p_{\mathrm{stu}}$: probability from the cross-encoder (CE) teacher and student model respectively</li> <li>$\alpha$: a hyperparameter to balance the two loss functions</li> <li>$L_{\mathrm{cont}}$: contrastive loss</li> </ul> <p>ì—¬ê¸°ì„œëŠ” SimLM ëª¨ë¸ì„ cross-encoder (teacher model)ë¡œ ì‚¬ìš©í•˜ì˜€ë‹¤ê³  í•œë‹¤.</p> <h1 id="multilingual-e5">Multilingual E5</h1> <p>e5-multilingual ëª¨ë¸ì€ ë‹¤ìŒê³¼ ê°™ì€ ë‘ ë‹¨ê³„ì˜ í•™ìŠµ ì „ëµì„ í†µí•´ í•™ìŠµë˜ì—ˆë‹¤.</p> <h2 id="training-two-stage-methodology">Training: Two-stage methodology</h2> <ol> <li>Weakly-supervised contrastive pre-training on billions of text pairs</li> <li>Supervised finetuning on small quantity of high-quality labeled data</li> </ol> <h3 id="1-weakly-supervised-contrastive-pre-training">(1) Weakly-supervised contrastive pre-training</h3> <p>ì•½ 1B ì •ë„ì˜ ë‹¤êµ­ì–´ ë°ì´í„°ì…‹(text pairs)ì„ ì´ìš©í•˜ì—¬ í•™ìŠµí–ˆë‹¤.</p> <p><img src="https://i.imgur.com/hNlpaUx.png" alt="Image" width="45%"/></p> <p>í•™ìŠµ loss ì˜ ê²½ìš°, in-batch negatives ê°€ ì ìš©ëœ InfoNCE contrastive loss ë¥¼ ì‚¬ìš©í–ˆë‹¤. ë‹¤ë¥¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ì˜ì–´ ì „ìš© e5 ëª¨ë¸ì„ í•™ìŠµí• ë•Œì™€ ë™ì¼í•˜ê²Œ ì„¤ì •í•˜ì˜€ë‹¤ê³  í•œë‹¤.</p> <p>ì°¸ê³ ë¡œ, In-batch negative ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ ì‹œ ë°°ì¹˜(batch) ë‚´ì˜ ë‹¤ë¥¸ ìƒ˜í”Œë“¤ì„ ë¶€ì • ìƒ˜í”Œ(negative sample)ë¡œ í™œìš©í•˜ëŠ” ê¸°ë²•ì´ë‹¤. í•´ë‹¹ ë°©ì‹ì— ëŒ€í•´ ëª‡ê°€ì§€ ì˜ê²¬ì´ ìˆë‹¤ë©´â€¦</p> <ul> <li>ì´ëŠ” ë³„ë„ì˜ negative sampling ì‘ì—…ì—†ì´ í˜„ì¬ ë°°ì¹˜ì— í¬í•¨ëœ ë°ì´í„°ë§Œìœ¼ë¡œ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆì–´ íš¨ìœ¨ì ì´ë‹¤.</li> <li>ë˜í•œ, ë°°ì¹˜ ì‚¬ì´ì¦ˆê°€ ì¶©ë¶„íˆ í¬ë‹¤ë©´ ì´ëŸ° ë‹¨ìˆœí•œ ì „ëµì´ ë‹¤ë¥¸ ë°©ì‹ë³´ë‹¤ í›¨ì”¬ íš¨ìœ¨ì ì´ê³  ì•ˆì •ì ì¸ í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤ê³  ë§í•œë‹¤.</li> <li>ë¬¼ë¡ , batch size ë¥¼ ì¤„ì´ê³  hard negatives ë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒë„ ë‚˜ì˜ì§„ ì•Šì§€ë§Œ, 100M ì´ìƒì˜ í° ë°ì´í„°ì…‹ì—ì„œ hard negatives ë¥¼ ì°¾ì•„ë‚´ëŠ”ê±´ ì‰½ì§€ ì•Šë‹¤ (non-trivial).</li> </ul> <h3 id="2-supervised-finetuning">(2) Supervised finetuning</h3> <p>ì´ ë‹¨ê³„ì—ì„œëŠ” in-batch negatives ì „ëµ ì™¸ì—ë„, mined hard negatives ì™€ êµì°¨ ì¸ì½”ë” ëª¨ë¸(cross-encoder model)ë¡œë¶€í„°ì˜ ì§€ì‹ ì¦ë¥˜(knowledge distillation)ë¥¼ ì „ëµì„ ì¶”ê°€ë¡œ í™œìš©í•˜ì—¬ ì„ë² ë”© í’ˆì§ˆì„ ë”ìš± í–¥ìƒì‹œì¼°ë‹¤.</p> <p><strong>Instruction model</strong> ì˜ ê²½ìš°, Reference [2] ì—ì„œ ì‚¬ìš©í–ˆë˜ GPT-3/4 ê¸°ë°˜ í•©ì„± ë°ì´í„°ë¥¼ ì´ìš©í•˜ì—¬ embedding model ì— ëŒ€í•´ instruction íŠœë‹ì„ ì§„í–‰í•˜ì˜€ë‹¤.</p> <h2 id="training-hyper-parameters">Training: hyper-parameters</h2> <p>mE5 (multilingual E5) ëª¨ë¸ì€ ê°ê° ë‹¤ìŒê³¼ ê°™ì€ ëª¨ë¸ë¡œë¶€í„° ì´ˆê¸°í™”ë˜ì—ˆë‹¤.</p> <ol> <li>mE5small: multilingual MiniLM</li> <li>mE5base: xlm-roberta-base</li> <li>mE5large: xlm-roberta-large</li> </ol> <p>Learning Rate ì˜ ê²½ìš° ëª¨ë¸ ì‚¬ì´ì¦ˆê°€ ì»¤ì§ˆìˆ˜ë¡ ë” ë‚®ê²Œ ì„¤ì •í–ˆë‹¤.</p> <ul> <li>Pretraining: small, base, large ê°ê° {3, 2, 1}Ã—10â»â´</li> <li>Finetuning: small, base, large ê°ê° {3, 2, 1}Ã—10â»âµ</li> </ul> <h2 id="evaluation">Evaluation</h2> <ul> <li>MTEB benchmark</li> <li>MIRACL multilingual retrieval benchmark (MAP, nDCG)</li> <li>Bitext mining</li> </ul> <h2 id="references">References</h2> <p>Papers</p> <ul> <li>[1] <a href="https://arxiv.org/pdf/2402.05672">Multilingual E5 Text Embeddings: A Technical Report</a></li> <li>[2] <a href="https://arxiv.org/pdf/2402.05672">Improving Text Embeddings with Large Language Models</a></li> <li>[3] <a href="https://arxiv.org/abs/2212.03533">Text Embeddings by Weakly-Supervised Contrastive Pre-training</a></li> </ul> <p>Code</p> <ul> <li>e5-evaluation: https://github.com/microsoft/unilm/tree/master/e5</li> <li>sentence-transformers: https://github.com/UKPLab/sentence-transformers</li> </ul> <p>Models</p> <ul> <li>í•œêµ­ì–´ íŠ¹í™” ì„ë² ë”© ëª¨ë¸: https://github.com/nlpai-lab/KURE</li> </ul> <p>Blog</p> <ul> <li><a href="https://yjoonjang.medium.com/koe5-%EC%B5%9C%EC%B4%88%EC%9D%98-%ED%95%9C%EA%B5%AD%EC%96%B4-%EC%9E%84%EB%B2%A0%EB%94%A9-%EB%AA%A8%EB%8D%B8-multilingual-e5-finetune-22fa7e56d220">KURE: ìµœì´ˆì˜ í•œêµ­ì–´ íŠ¹í™” ì„ë² ë”© ëª¨ë¸</a></li> </ul>]]></content><author><name></name></author><category term="microsoft"/><category term="encoder"/><summary type="html"><![CDATA[Original E5]]></summary></entry><entry><title type="html">ìƒˆë¡œìš´ Bert ëª¨ë¸: ModernBERT</title><link href="https://zzong2006.github.io/blog/2025/modern-bert/" rel="alternate" type="text/html" title="ìƒˆë¡œìš´ Bert ëª¨ë¸: ModernBERT"/><published>2025-01-01T00:00:00+00:00</published><updated>2025-01-01T00:00:00+00:00</updated><id>https://zzong2006.github.io/blog/2025/modern-bert</id><content type="html" xml:base="https://zzong2006.github.io/blog/2025/modern-bert/"><![CDATA[<p>ê¸°ì¡´ BERT family ë“¤ì˜ ì„±ëŠ¥ê³¼ ì†ë„ë¥¼ ëª¨ë‘ ì´ê¸¸ ìˆ˜ ìˆëŠ” ModernBERT ê°€ ë‚˜ì™”ë‹¤ê³  í•œë‹¤.</p> <p>ì—¬ê¸°ì„œ ì„±ëŠ¥ì´ë¼í•˜ë©´ GLUE score ë¥¼ ì˜ë¯¸í•˜ê³ , ì†ë„ë¼ í•˜ë©´ ì´ˆë‹¹ í† í° ì²˜ë¦¬ë¥¼ ì˜ë¯¸í•œë‹¤. ì•„ë˜ ê·¸ë˜í”„ë¥¼ ì°¸ê³ í•˜ì.</p> <p><img src="https://cdn-lfs.hf.co/datasets/huggingface/documentation-images/32fba11bd9e3594f1f9b9eba90e4651cc565275afa85af5c68eae87aad19ccd0?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27modernbert_pareto_curve.png%3B+filename%3D%22modernbert_pareto_curve.png%22%3B&amp;response-content-type=image%2Fpng&amp;Expires=1735985095&amp;Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNTk4NTA5NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9kYXRhc2V0cy9odWdnaW5nZmFjZS9kb2N1bWVudGF0aW9uLWltYWdlcy8zMmZiYTExYmQ5ZTM1OTRmMWY5YjllYmE5MGU0NjUxY2M1NjUyNzVhZmE4NWFmNWM2OGVhZTg3YWFkMTljY2QwP3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiZyZXNwb25zZS1jb250ZW50LXR5cGU9KiJ9XX0_&amp;Signature=TIQgVGH8PBIQYSnxWKvBRBEN7U4UGxL8HBZedeYaAhSg5I4OxXHyXgUYlZ5IWSWzzGof48OIDb8eiam-afiVsxNzT9PhmctUUYmYSZKRn2CuS6tOzkpBUjZ%7EbxridS6pXebaEr%7E-EcLpfNms20p9DTxbYtJm4qGuaNd7zlJabh7ihNbnagwPqFUNm9k7%7EtNSsuoJ2gsRLt4h-aONxmKP9dQZ0woIPzSf%7E3Ab3nmzeAYOWtECeXFa5Gm-AQ4RJBFd0F5v3GlQ0YbGNZ%7EDbx5SQkcS-GGRLz34GycQNwU83hBx77ylxuXSKXInHzIOSXT2I70X3rSGh17bXacspmidWw__&amp;Key-Pair-Id=K3RPWS32NSSJCE" style="width: 100%;"/></p> <h2 id="íŠ¹ì§•">íŠ¹ì§•</h2> <p>ModernBERT ëŠ” ê¸°ì¡´ì˜ BERT ëŒ€ë¹„ ë‹¤ìŒê³¼ ê°™ì€ ì¥ì ì„ ê°€ì§€ê³  ìˆë‹¤.</p> <ol> <li>8k í† í° ì‚¬ì´ì¦ˆ ì§€ì›: ëŒ€ë¶€ë¶„ì˜ BERT ì‹œë¦¬ì¦ˆëŠ” ìµœëŒ€ 512 í† í° ì‚¬ì´ì¦ˆë¥¼ ì§€ì›í–ˆë‹¤.</li> <li>ë©”ëª¨ë¦¬ íš¨ìœ¨ì : Kaggle ì—ì„œ ê°€ì¥ ë§ì´ ì“°ì´ëŠ” DeBERTaV3 ëª¨ë¸ë³´ë‹¤ 1/5 ì •ë„ ë©”ëª¨ë¦¬ë§Œ í•„ìš”í•˜ë‹¤.</li> <li>ì¶”ë¡  ì†ë„ê°€ ë¹ ë¦„: DeBERTa ëª¨ë¸ë³´ë‹¤ ê¸°ë³¸ì ìœ¼ë¡œ 2ë°° ë¹ ë¥´ë©°, mixed length ì¸ ì¼€ì´ìŠ¤ì—ì„œëŠ” ìµœëŒ€ 4ë°° ë” ë¹ ë¥´ë‹¤.</li> </ol> <p>ê·¸ ì™¸ì—ë„ í•™ìŠµ ë°ì´í„°ì…‹ ì‚¬ì´ì¦ˆê°€ 2T token ì´ë¼ëŠ” íŠ¹ì§•ì´ ìˆë‹¤.</p> <p>ì•„ë˜ì˜ ì„¸ê°€ì§€ ë°©ë²•ë¡ ì„ ì ìš©í•´ì„œ ModernBERT ë¥¼ ë§Œë“¤ì—ˆë‹¤ê³  í•œë‹¤.</p> <ol> <li>í˜„ëŒ€í™”ëœ transformer êµ¬ì¡°</li> <li>Particular attention to efficiency</li> <li>í•™ìŠµ ë°ì´í„°ì…‹ì„ í˜„ëŒ€ì ìœ¼ë¡œ ì¬êµ¬ì„±</li> </ol> <h2 id="recipe-1-transformer-êµ¬ì¡°-ì—…ë°ì´íŠ¸">(Recipe 1) Transformer êµ¬ì¡° ì—…ë°ì´íŠ¸</h2> <p>Llama2 íŒ¨ë°€ë¦¬ ëª¨ë¸ì—ì„œ ì‚¬ìš©ëœ Transformer++ êµ¬ì¡°ì— ì˜ê°ì„ ì–»ì–´ì„œ ë‹¤ìŒê³¼ ê°™ì€ ì—…ë°ì´íŠ¸ë¥¼ ì ìš©í–ˆë‹¤ê³  í•œë‹¤.</p> <ul> <li>Old positional encoding ì„ RoPE(rotary positional embeddings) ë¡œ ëŒ€ì²´</li> <li>ê¸°ì¡´ BERT ì˜ GeLU activation function ì´ í¬í•¨ëœ MLP layers ë¥¼ GeGLU layers ë¡œ êµì²´</li> <li>ë¶ˆí•„ìš”í•œ bias term ì„ ì œê±°í•´ì„œ parameter ìˆ˜ë¥¼ ì¤„ì´ëŠ”ë° ê¸°ì—¬</li> <li>ì„ë² ë”© ë ˆì´ì–´ ì´í›„ì— normalization layer ë¥¼ ì¶”ê°€</li> </ul> <h2 id="recipe-2-attention-ë°©ì‹-ë³€ê²½ìœ¼ë¡œ-íš¨ìœ¨ì„±-ë†’ì´ê¸°">(Recipe 2) Attention ë°©ì‹ ë³€ê²½ìœ¼ë¡œ íš¨ìœ¨ì„± ë†’ì´ê¸°</h2> <p>Flash Attention 2 ë¥¼ í™œìš©í•˜ì—¬ ì•„ë˜ì™€ ê°™ì€ ì—…ë°ì´íŠ¸ë¥¼ ì ìš©í–ˆë‹¤.</p> <ol> <li>Attention ë³€ê²½: local and global</li> <li>Sequence Packing ì ìš©</li> <li>í•˜ë“œì›¨ì–´ ë°ì¶¤í˜• ëª¨ë¸ ë””ìì¸</li> </ol> <h3 id="2-1-local-and-global-attention">2-1. Local and Global Attention</h3> <p>ê¸°ì¡´ BERT ì—ì„œëŠ” ëª¨ë“  ë ˆì´ì–´ì—ì„œ ëª¨ë“  input token ë“¤ì— ëŒ€í•´ attention ë¡œì§ì„ ì ìš©í–ˆë‹¤. ì´ë¥¼ full attention ì´ë¼ê³  í‘œí˜„í•´ë³´ì.</p> <p>ModernBert ì—ì„œëŠ” full attention ë°©ì‹ì„ global ê³¼ local attention ìœ¼ë¡œ ë‚˜ëˆ´ë‹¤.</p> <ul> <li>global attention: ë§¤ 3ë²ˆì§¸ layer ì—ì„œ ëª¨ë“  input token ë“¤ì— ëŒ€í•´ attention ë¡œì§ì„ ì ìš©</li> <li>local attention: ë‚˜ë¨¸ì§€ layer ì—ì„œ sliding window ë°©ì‹ìœ¼ë¡œ <strong>ì¼ë¶€ input token ë“¤</strong>ì— ëŒ€í•´ attention ë¡œì§ì„ ì ìš© (window size: 128)</li> </ul> <p>ì´ëŠ” ë§ˆì¹˜ ì±…ì„ ì½ì„ë•Œì™€ ë¹„ìŠ·í•œë°, ëª¨ë“  ë¬¸ì¥ì— ëŒ€í•´ì„œ ì§‘ì¤‘í•˜ëŠ” ê²ƒ(full attention) ê³¼ ì£¼ìš” ì¤„ê±°ë¦¬ì™€ ì¼ë¶€ ë¬¸ì¥ì— ëŒ€í•´ì„œë§Œ ì§‘ì¤‘í•˜ëŠ” ê²ƒ(global and local attention) ì˜ ê°œë…ì  ì°¨ì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤.</p> <p>Attention ì˜ ê³„ì‚° ë³µì¡ë„ëŠ” í† í° ì‚¬ì´ì¦ˆì— ë”°ë¼ì„œ ê¸‰ì¦í•˜ë¯€ë¡œ, modernBert ëŠ” ê¸´ ë¬¸ì¥ì— ëŒ€í•´ì„œ íš¨ìœ¨ì ìœ¼ë¡œ ëŒ€ì²˜í•  ìˆ˜ ìˆë‹¤.</p> <h3 id="2-2-sequence-packing">2-2. Sequence Packing</h3> <p>ì¼ë°˜ì ìœ¼ë¡œ ì„œë¡œ ë‹¤ë¥¸ sequence length ë¥¼ ê°€ì§„ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ì„œëŠ” padding ì„ ì ìš©í•´ì•¼ í•œë‹¤.</p> <p>í•˜ì§€ë§Œ, ì´ ë°©ì‹ì€ ë‚­ë¹„ë˜ëŠ” íŒ¨ë”© í† í°ì— ì˜í•´ì„œ ì„±ëŠ¥ ì €í•˜ë¥¼ ë°œìƒì‹œí‚¤ê³ , íŒ¨ë”© í† í° ì—­ì‹œ ì–´ë– í•œ ì˜ë¯¸ë¡ ì  ê¸°ì—¬ë¥¼ í•˜ì§€ë„ ì•ŠëŠ”ë‹¤.</p> <p>ì´ëŸ° ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œ, ModernBert ëŠ” padding ì„ ë¶™ì´ì§€ ì•ŠëŠ” Sequence packing ë°©ì‹ì„ ì ìš©í–ˆë‹¤.</p> <p><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/modernbert/modernbert_unpadding.png" style="width: 100%;"/></p> <p>Sequence packing ì˜ íš¨ê³¼ë¥¼ ìµœëŒ€í™”í•˜ê¸° ìœ„í•´, ì‚¬ì „ í•™ìŠµ ê³¼ì •ì—ì„œ model max-length ì™€ ìµœëŒ€í•œ ê°€ê¹Œìš´ sequence ê¸¸ì´ì˜ ìˆœì„œë¡œ packing ì„ ì ìš©í•˜ì—¬ ì²˜ë¦¬ ì†ë„ë¥¼ ë†’ì˜€ë‹¤ê³  í•œë‹¤.</p> <h3 id="2-3-í•˜ë“œì›¨ì–´-ë°ì¶¤í˜•-ëª¨ë¸-ë””ìì¸">2-3. í•˜ë“œì›¨ì–´ ë°ì¶¤í˜• ëª¨ë¸ ë””ìì¸</h3> <p>ì—°êµ¬ì— ë”°ë¥´ë©´ deep &amp; narrow layer ì¡°í•©ì´ wide &amp; shallow layer ì¡°í•©ë³´ë‹¤ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²½ìš°ê°€ ë§ë‹¤. í•˜ì§€ë§Œ trade-off ê°€ ë°œìƒí•˜ëŠ”ë°, ëª¨ë¸ layer ê°€ ê¹Šì„ìˆ˜ë¡ ë³‘ë ¬í™”ê°€ ì¤„ì–´ë“¤ê³  ë”°ë¼ì„œ ë™ì¼í•œ íŒŒë¼ë§¤í„° ê°œìˆ˜ë¼ë„ ì†ë„ê°€ ëŠë ¤ì§€ê²Œ ëœë‹¤.</p> <p>ì¼ë°˜ì ì¸ GPU ì‚¬ì–‘ì´ RTX 3090/4090 ì •ë„ ê¸‰ì´ë¼ëŠ”ê±¸ ê°€ì •í•˜ê³ , ì œí•œëœ grid search ë¥¼ í†µí•´ì„œ ìµœì ì˜ ëª¨ë¸ ë””ìì¸ì„ ì°¾ì•˜ë‹¤ê³  í•œë‹¤.</p> <p>ê·¸ ê²°ê³¼, base ëŠ” 150M ì •ë„, large ëŠ” 400M ì •ë„ í¬ê¸°ì˜ ëª¨ë¸ì´ ë˜ì—ˆìœ¼ë©°, ì„ë² ë”© í¬ê¸°ëŠ” 768 (base) ì™€ 1024 (large) ë¡œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.</p> <h2 id="recipe-3-í•™ìŠµ-ë°ì´í„°ì…‹-ì¬êµ¬ì„±">(Recipe 3) í•™ìŠµ ë°ì´í„°ì…‹ ì¬êµ¬ì„±</h2> <p>ê¸°ì¡´ì˜ DeBERTaV3 ê°™ì€ ëª¨ë¸ë“¤ì€ Wikipedia and Wikibooks ì™€ ê°™ì´ ê³ í’ˆì§ˆ ë°ì´í„°ë§Œ í•™ìŠµì…‹ìœ¼ë¡œ êµ¬ì„±í•œ ë°ì´í„°ë¡œë§Œ í•™ìŠµí–ˆë‹¤ (single text modality).</p> <p>í•˜ì§€ë§Œ modernBert ëŠ” web documents, code, and scientific articles ê°™ì€ ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ë°ì´í„°ë„ í•™ìŠµ ë°ì´í„°ì…‹ì„ í™œìš©í•œë‹¤.</p> <p>ì´ëŸ° í•™ìŠµ ë°ì´í„°ì…‹ì˜ ë³€í™”ëŠ” ModernBERT ê°€ í”„ë¡œê·¸ë˜ë° ê´€ë ¨ task ì—ì„œ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²ƒìœ¼ë¡œ ì¦ëª…í•  ìˆ˜ ìˆê² ë‹¤.</p> <h2 id="í•™ìŠµ-í”„ë¡œì„¸ìŠ¤">í•™ìŠµ í”„ë¡œì„¸ìŠ¤</h2> <p>ê¸°ì¡´ì˜ BERT í•™ìŠµ ë°©ì‹ì„ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ë˜, ë³„ íš¨ê³¼ê°€ ì—†ëŠ” next-sentence prediction ëª©ì í•¨ìˆ˜ë¥¼ ì œê±°í•˜ê³ , masking rate ë¥¼ 15% ì—ì„œ 30% ë¡œ ì¦ê°€ì‹œì¼°ë‹¤.</p> <p>ê·¸ë¦¬ê³  2T ë°ì´í„°ì…‹ì„ í•œë²ˆì— í•™ìŠµí•˜ì§€ ì•Šê³ , ì´ 3 ë‹¨ê³„ì˜ í•™ìŠµì„ ê±°ì³¤ë‹¤.</p> <ol> <li>1.7T ì˜ ë°ì´í„°ëŠ” 1024 í† í° ì‚¬ì´ì¦ˆë¡œ í•™ìŠµ</li> <li>ë‚˜ë¨¸ì§€ 250B í† í°ì€ 8192 í† í° ì‚¬ì´ì¦ˆë¡œ í•™ìŠµ</li> <li>ë§ˆì§€ë§‰ìœ¼ë¡œ ë‚˜ë¨¸ì§€ 50B í† í°ì€ ê¸¸ì´ë¥¼ ëœë¤ìœ¼ë¡œ ìƒ˜í”Œë§í•˜ì—¬ í•™ìŠµ</li> </ol> <p>ì´ëŠ” ProLong ì´ë¼ëŠ” ê²ƒì—ì„œ ì˜ê°ì„ ë°›ì•˜ë‹¤ê³  í•˜ëŠ”ë°, êµ¬ì²´ì ì¸ ë‚´ìš©ì€ í™•ì¸í•´ë³´ì§€ ì•Šì•„ì„œ ì˜ ëª¨ë¥´ê² ë‹¤.</p> <p>ì´ ì™¸ì—ë„ ì•„ë˜ ë‘ê°€ì§€ íŠ¸ë¦­ìœ¼ë¡œ ì¢€ ë” íš¨ìœ¨ì ì¸ í•™ìŠµì´ ê°€ëŠ¥í–ˆë‹¤ê³  í•œë‹¤.</p> <ol> <li>Batch Size warming up: ë°°ì¹˜ ì‚¬ì´ì¦ˆë¥¼ í•™ìŠµ ì´ˆê¸°ì—ëŠ” ì‘ê²Œ ê°€ì ¸ê°”ë‹¤ê°€ ì‹œê°„ì´ ì§€ë‚ ìˆ˜ë¡ ì¡°ê¸ˆì”© ëŠ˜ë ¤ê°€ëŠ” ë°©ë²•</li> <li>Tiling Model weight: Large ëª¨ë¸ weight ë¥¼ ì´ˆê¸°í™”í• ë•Œ í•™ìŠµëœ Base ëª¨ë¸ì„ í™œìš©í•˜ì—¬ loss ìˆ˜ë ´ ì†ë„ë¥¼ ë†’ì´ëŠ” ë°©ë²•</li> </ol> <h2 id="ëŠë‚€ì ">ëŠë‚€ì </h2> <p>ìµœê·¼ 8k ìˆ˜ì¤€ì˜ ì„ë² ë”©ì„ ìƒì„±í•  ìˆ˜ ìˆëŠ” ì¸ì½”ë” ì „ëµë“¤ì´ ë§ì´ ë‚˜ì˜¤ëŠ”ê²ƒ ê°™ë‹¤.</p> <p>FlashAttention ê¸°ë°˜ì˜ Sequence Packing ì„ ì ìš©í–ˆë‹¤ëŠ” ì , attention ë°©ì‹ì„ Layer ë§ˆë‹¤ ë‹¤ë¥´ê²Œ ì ìš©í•œ ì ë„ í¥ë¯¸ë¡œì› ë‹¤. ìƒë‹¹íˆ ë°°ì›Œë³´ê³  ì‹¶ì€ ê¸°ìˆ ë“¤ì´ë‹¤.</p> <p>ìµœì ì˜ ë ˆì´ì–´ ë””ìì¸ì„ ì°¾ëŠ”ê²ƒì€ grid search ë¥¼ ì´ìš©í–ˆë‹¤ê³  í•˜ë‹ˆ, ì—­ì‹œ ì´ ë¶€ë¶„ì€ ë…¸ë‹¤ê°€ ì•„ë‹ˆë©´ ì•ˆë˜ëŠ” ì¼ì¸ë“¯ ì‹¶ë‹¤.</p> <p>ê·¸ë¦¬ê³  ë‹¨ìˆœíˆ ê³ í’ˆì§ˆ ë°ì´í„°ê°€ ë¬¸ì œê°€ ì•„ë‹ˆë¼ ë” ë‹¤ì–‘í•œ ë°ì´í„° ì—­ì‹œ ì„±ëŠ¥ì— ì¤‘ìš”í•œ ì˜í–¥ì„ ë¯¸ì¹œë‹¤ëŠ” ê²ƒë„ ì¤‘ìš”í•œ í¬ì¸íŠ¸ì¸ë“¯ ì‹¶ë‹¤.</p> <h2 id="references">References</h2> <p>Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference</p> <ul> <li>blog: https://huggingface.co/blog/modernbert</li> <li>paper: https://huggingface.co/papers/2412.13663</li> </ul>]]></content><author><name></name></author><category term="llm"/><category term="encoder"/><category term="bert"/><category term="flash_attention"/><summary type="html"><![CDATA[ê¸°ì¡´ BERT family ë“¤ì˜ ì„±ëŠ¥ê³¼ ì†ë„ë¥¼ ëª¨ë‘ ì´ê¸¸ ìˆ˜ ìˆëŠ” ModernBERT ê°€ ë‚˜ì™”ë‹¤ê³  í•œë‹¤.]]></summary></entry><entry><title type="html">SFT ë°ì´í„°ì…‹ì˜ ë…¸ì´ì¦ˆë¥¼ ì¤„ì—¬ë³´ì</title><link href="https://zzong2006.github.io/blog/2024/robust-ft/" rel="alternate" type="text/html" title="SFT ë°ì´í„°ì…‹ì˜ ë…¸ì´ì¦ˆë¥¼ ì¤„ì—¬ë³´ì"/><published>2024-12-30T00:00:00+00:00</published><updated>2024-12-30T00:00:00+00:00</updated><id>https://zzong2006.github.io/blog/2024/robust-ft</id><content type="html" xml:base="https://zzong2006.github.io/blog/2024/robust-ft/"><![CDATA[<p>Downstream task ë¥¼ ìœ„í•œ LLM ëª¨ë¸ì„ í•™ìŠµí•  ë•Œ, íŒŒì¸íŠœë‹(=SFT) ë°ì´í„°ì— ë…¸ì´ì¦ˆê°€ ìˆëŠ” ê²½ìš°, ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì €í•˜ëœë‹¤.</p> <p>ì´ ë…¼ë¬¸ì—ì„œëŠ” RobustFT ë¼ëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ì—¬, ë°ì´í„°ì— ë…¸ì´ì¦ˆê°€ ìˆëŠ”ì§€ ì—¬ë¶€ë¥¼ íƒì§€í•˜ê³ , ë…¸ì´ì¦ˆê°€ ìˆëŠ” ê²½ìš° ì¬ë ˆì´ë¸”ë§ì„ ìˆ˜í–‰í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¨ë‹¤.</p> <h2 id="ë…¸ì´ì¦ˆ-íƒì§€-noise-identification">ë…¸ì´ì¦ˆ íƒì§€ (noise identification)</h2> <p>ì—¬ê¸°ì„œ ë§í•˜ëŠ” ë°ì´í„°ì— í¬í•¨ëœ â€œë…¸ì´ì¦ˆâ€ë€, ì—¬ëŸ¬ LLM ì˜ ì‘ë‹µì´ ì¼ê´€ì„±ì´ ì—†ëŠ” ê²½ìš°ë¥¼ ë§í•œë‹¤. ì¦‰, prompt ì™€ response ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, ì—¬ëŸ¬ LLM ì˜ ì‘ë‹µì´ ì¼ê´€ì„±ì´ ì—†ëŠ” ê²½ìš° ë…¸ì´ì¦ˆê°€ ìˆë‹¤ê³  íŒë‹¨í•œë‹¤.</p> <h3 id="methods">Methods</h3> <p>ì—¬ëŸ¬ ì „ë¬¸ê°€ LLMs ê³¼ Checker ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì˜ ë…¸ì´ì¦ˆë¥¼ ì‹ë³„í•œë‹¤.</p> <ol> <li>ì–´ë–¤ base LLM ì„ ì‚¬ìš©í•˜ì—¬ ì •ë‹µ $y$ ê°€ ìˆëŠ” query $q_i$ ì— ëŒ€í•´ ì‘ë‹µ $\hat{y}_i$ ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì„ ìƒê°í•´ë³´ì.</li> <li>LLM ìœ¼ë¡œ (1) step-by-step reasoning (2) reflection ì„ ê³„ì† ë°˜ë³µí•˜ë©´ì„œ ì‘ë‹µ $\hat{y}^{reas}_i$ ë¥¼ ìƒì„±í•˜ë„ë¡ í•œë‹¤.</li> <li>Checker ëŠ” ì§€ê¸ˆê¹Œì§€ì˜ ì‘ë‹µë“¤ ($y,\hat{y}_i, \hat{y}^{reas}_i$) ì„ ì´ìš©í•´ì„œ ë…¸ì´ì¦ˆê°€ ìˆëŠ”ì§€ ì—¬ë¶€ë¥¼ íŒë‹¨í•œë‹¤.</li> <li>Checker ëŠ” ì‘ë‹µì˜ ì¼ê´€ì„± ì •ë„ë¥¼ 0 ë˜ëŠ” 1 ì˜ ê°’ìœ¼ë¡œ íŒë‹¨í•˜ëŠ”ë°, 0 ì´ë©´ ë…¸ì´ì¦ˆê°€ ìˆëŠ” ê²ƒì´ê³  1 ì´ë©´ ë…¸ì´ì¦ˆê°€ ì—†ëŠ” ê²ƒì´ë‹¤.</li> </ol> <p>ì—¬ê¸°ì„œ Checker ë©”ì»¤ë‹ˆì¦˜ì€ ìƒë‹¹íˆ naive í•œë°, ë°ì´í„°ì…‹ë§ˆë‹¤ ë©”ì»¤ë‹ˆì¦˜ì´ ë‹¤ë¥´ë‹¤. ì˜ˆë¥¼ ë“¤ì–´, MMLU ê°™ì€ ê²½ìš°ëŠ” ì‘ë‹µë“¤ì˜ ì •ë‹µì„ ì¶”ì¶œí•´ì„œ ì„œë¡œ ê°™ì€ì§€ ë¹„êµí•˜ëŠ” ê²ƒìœ¼ë¡œ ë…¸ì´ì¦ˆ ì—¬ë¶€ë¥¼ íŒë‹¨í•œë‹¤.</p> <h3 id="ì°¸ê³ ">ì°¸ê³ </h3> <p>ì‹¤í—˜ì—ì„œ LLM ìœ¼ë¡œ Gemma2-9B, Llama3.1-8B ë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤.</p> <h2 id="ë…¸ì´ì¦ˆ-ì œê±°-de-noising">ë…¸ì´ì¦ˆ ì œê±° (de-noising)</h2> <ol> <li>Review Agent: context-enhanced reasoning with clean samples to store label noisy instances</li> <li>a perplexity-based data selection mechanism to exclude samples with low confidence scores</li> </ol> <h2 id="ëŠë‚€ì ">ëŠë‚€ì </h2> <p>ì •ë‹µ(ë˜ëŠ” golden reference) ì´ ì—†ëŠ” ê²½ìš° Checker ê°€ ì˜ ì‘ë™í•˜ì§€ ì•Šì„ê²ƒ ê°™ë‹¤.</p> <p>ë°ì´í„° ì •ì œí•˜ëŠ” ê±´ ì¢‹ì€ë°, ë‹¤ìˆ˜ì˜ LLM ì´ìš©í•´ì„œ ì •ì œí•˜ëŠ” ë¹„ìš©ì€ ë˜ ë‹¤ë¥¸ ì–˜ê¸°ë‹¤.</p> <h2 id="references">References</h2> <p>RobustFT: Robust Supervised Fine-tuning for Large Language Models under Noisy Response</p> <ul> <li>paper: https://huggingface.co/papers/2412.14922</li> <li>code: https://github.com/luo-junyu/RobustFT</li> </ul>]]></content><author><name></name></author><category term="llm"/><category term="sft"/><category term="data_preprocessing"/><summary type="html"><![CDATA[ë°ì´í„° ë””ë…¸ì´ì§• í”„ë ˆì„ì›Œí¬ RobustFT]]></summary></entry><entry><title type="html">a post with image galleries</title><link href="https://zzong2006.github.io/blog/2024/photo-gallery/" rel="alternate" type="text/html" title="a post with image galleries"/><published>2024-12-04T01:59:00+00:00</published><updated>2024-12-04T01:59:00+00:00</updated><id>https://zzong2006.github.io/blog/2024/photo-gallery</id><content type="html" xml:base="https://zzong2006.github.io/blog/2024/photo-gallery/"><![CDATA[<p>The images in this post are all zoomable, arranged into different mini-galleries using different libraries.</p> <h2 id="lightbox2"><a href="https://lokeshdhakar.com/projects/lightbox2/">Lightbox2</a></h2> <p><a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-2500.jpg" data-lightbox="roadtrip"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-200.jpg"/></a> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg" data-lightbox="roadtrip"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg"/></a> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg" data-lightbox="roadtrip"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg"/></a></p> <hr/> <h2 id="photoswipe"><a href="https://photoswipe.com/">PhotoSwipe</a></h2> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--getting-started"> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg" data-pswp-width="1669" data-pswp-height="2500" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg" alt=""/> </a> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/7/img-2500.jpg" data-pswp-width="1875" data-pswp-height="2500" data-cropped="true" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/7/img-200.jpg" alt=""/> </a> <a href="https://unsplash.com" data-pswp-src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg" data-pswp-width="2500" data-pswp-height="1666" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg" alt=""/> </a> <div> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-2500.jpg" data-pswp-width="2500" data-pswp-height="1667" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-200.jpg" alt=""/> </a> </div> </div> <hr/> <h2 id="spotlight-js"><a href="https://nextapps-de.github.io/spotlight/">Spotlight JS</a></h2> <div class="spotlight-group"> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg"/> </a> </div> <div class="spotlight-group"> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/4/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/4/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/5/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/5/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-200.jpg"/> </a> </div> <hr/> <h2 id="venobox"><a href="https://veno.es/venobox/">Venobox</a></h2> <p><a class="venobox" data-gall="myGallery" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-2500.jpg"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-200.jpg"/></a> <a class="venobox" data-gall="myGallery" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg"/></a> <a class="venobox" data-gall="myGallery" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg"/></a></p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="images"/><summary type="html"><![CDATA[this is what included image galleries could look like]]></summary></entry><entry><title type="html">a post with typograms</title><link href="https://zzong2006.github.io/blog/2024/typograms/" rel="alternate" type="text/html" title="a post with typograms"/><published>2024-04-29T23:36:10+00:00</published><updated>2024-04-29T23:36:10+00:00</updated><id>https://zzong2006.github.io/blog/2024/typograms</id><content type="html" xml:base="https://zzong2006.github.io/blog/2024/typograms/"><![CDATA[<p>This is an example post with some <a href="https://github.com/google/typograms/">typograms</a> code.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">typograms
</span><span class="sb">+----+
|    |---&gt; My first diagram!
+----+</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <pre><code class="language-typograms">+----+
|    |---&gt; My first diagram!
+----+
</code></pre> <p>Another example:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">typograms
</span><span class="sb">.------------------------.
|.----------------------.|
||"https://example.com" ||
|'----------------------'|
| ______________________ |
||                      ||
||   Welcome!           ||
||                      ||
||                      ||
||  .----------------.  ||
||  | username       |  ||
||  '----------------'  ||
||  .----------------.  ||
||  |"*******"       |  ||
||  '----------------'  ||
||                      ||
||  .----------------.  ||
||  |   "Sign-up"    |  ||
||  '----------------'  ||
||                      ||
|+----------------------+|
.------------------------.</span>
<span class="p">```</span>
</code></pre></div></div> <p>which generates:</p> <pre><code class="language-typograms">.------------------------.
|.----------------------.|
||"https://example.com" ||
|'----------------------'|
| ______________________ |
||                      ||
||   Welcome!           ||
||                      ||
||                      ||
||  .----------------.  ||
||  | username       |  ||
||  '----------------'  ||
||  .----------------.  ||
||  |"*******"       |  ||
||  '----------------'  ||
||                      ||
||  .----------------.  ||
||  |   "Sign-up"    |  ||
||  '----------------'  ||
||                      ||
|+----------------------+|
.------------------------.
</code></pre> <p>For more examples, check out the <a href="https://google.github.io/typograms/#examples">typograms documentation</a>.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="diagrams"/><summary type="html"><![CDATA[this is what included typograms code could look like]]></summary></entry><entry><title type="html">a post that can be cited</title><link href="https://zzong2006.github.io/blog/2024/post-citation/" rel="alternate" type="text/html" title="a post that can be cited"/><published>2024-04-28T15:06:00+00:00</published><updated>2024-04-28T15:06:00+00:00</updated><id>https://zzong2006.github.io/blog/2024/post-citation</id><content type="html" xml:base="https://zzong2006.github.io/blog/2024/post-citation/"><![CDATA[<p>This is an example post that can be cited. The content of the post ends here, while the citation information is automatically provided below. The only thing needed is for you to set the <code class="language-plaintext highlighter-rouge">citation</code> key in the front matter to <code class="language-plaintext highlighter-rouge">true</code>.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="citation"/><summary type="html"><![CDATA[this is what a post that can be cited looks like]]></summary></entry><entry><title type="html">a post with echarts</title><link href="https://zzong2006.github.io/blog/2024/echarts/" rel="alternate" type="text/html" title="a post with echarts"/><published>2024-01-26T16:03:00+00:00</published><updated>2024-01-26T16:03:00+00:00</updated><id>https://zzong2006.github.io/blog/2024/echarts</id><content type="html" xml:base="https://zzong2006.github.io/blog/2024/echarts/"><![CDATA[<p>This is an example post with some <a href="https://echarts.apache.org/">echarts</a> code.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">echarts
</span><span class="sb">{
  "title": {
    "text": "ECharts Getting Started Example"
  },
  "responsive": true,
  "tooltip": {},
  "legend": {
    "top": "30px",
    "data": ["sales"]
  },
  "xAxis": {
    "data": ["Shirts", "Cardigans", "Chiffons", "Pants", "Heels", "Socks"]
  },
  "yAxis": {},
  "series": [
    {
      "name": "sales",
      "type": "bar",
      "data": [5, 20, 36, 10, 10, 20]
    }
  ]
}</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <pre><code class="language-echarts">{
  "title": {
    "text": "ECharts Getting Started Example"
  },
  "responsive": true,
  "tooltip": {},
  "legend": {
    "top": "30px",
    "data": ["sales"]
  },
  "xAxis": {
    "data": ["Shirts", "Cardigans", "Chiffons", "Pants", "Heels", "Socks"]
  },
  "yAxis": {},
  "series": [
    {
      "name": "sales",
      "type": "bar",
      "data": [5, 20, 36, 10, 10, 20]
    }
  ]
}
</code></pre> <p>Note that this library offer support for both light and dark themes. You can switch between them using the theme switcher in the top right corner of the page.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="charts"/><summary type="html"><![CDATA[this is what included echarts code could look like]]></summary></entry></feed>