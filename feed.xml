<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://zzong2006.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://zzong2006.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-01-19T12:15:34+00:00</updated><id>https://zzong2006.github.io/feed.xml</id><title type="html">Believe I.Y.</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">ML Recap - Beta Distribution</title><link href="https://zzong2006.github.io/blog/2025/beta-distribution/" rel="alternate" type="text/html" title="ML Recap - Beta Distribution"/><published>2025-01-19T23:00:00+00:00</published><updated>2025-01-19T23:00:00+00:00</updated><id>https://zzong2006.github.io/blog/2025/beta-distribution</id><content type="html" xml:base="https://zzong2006.github.io/blog/2025/beta-distribution/"><![CDATA[<p>확률 내용이긴 하지만, ML 에서도 자주 사용되는 beta distribution 에 대해서 정리해보자.</p> <hr/> <p>베타 분포는 확률의 분포를 나타내는 것으로 이해할 수 있다. 즉, 우리가 어떤 확률이 무엇인지 모를 때 그 확률의 모든 가능한 값을 나타낸다.</p> <blockquote> <p>The Beta distribution is best for representing <strong>a probabilistic distribution of probabilities</strong>: the case where we don’t know what a probability is in advance, but we have some reasonable guesses.</p> </blockquote> <p>예를 들어 어떤 야구 선수의 타율에 대해서 베타 분포를 사용할 수 있다. 평균 타율이 0.26 정도이고, 0.21 과 0.35 사이에 타율이 분포(prior)하고 있는 야구선수에 대해서 Beta 분포로 표현하자면 $\alpha = 81, \beta = 219$ 로 아래와 같이 모델링할 수 있다.</p> <p><img src="https://i.sstatic.net/RJDrz.png" alt="beta distribution" width="50%"/></p> <p>베타 분포 밀도 그래프에서 x축은 선수의 타율을 나타낸다. 따라서 이 그래프에서 y축이 확률(또는 더 정확히는 probability density)일 뿐만 아니라 x축도 확률이다 (타율은 결국 안타의 확률이다).</p> <p>참고로 베타 분포의 평균은 $\alpha / (\alpha + \beta)$ 이다.</p> <p>베타 분포가 유용한 이유는 새로운 피드백에 대한 반영이 간단하다는 점이다. 예를 들어, 위의 선수가 300 번 나가서 100번 안타를 쳤다고 가정해보자. 이러한 정보를 반영하기 위해서 아래와 같은 수식을 활용할 수 있다.</p> \[\mbox{Beta}(\alpha_0+\mbox{hits}, \beta_0+\mbox{misses})\] <p>여기서 $\alpha_0$ 와 $\beta_0$ 는 초기 베타 분포의 파라미터이다. 위 안타 사례에 의하면 alpha 쪽은 100, beta 쪽은 200 (300 - 100) 을 증가시키면 된다.</p> <p><img src="https://i.sstatic.net/oBgYH.png" alt="beta distribution" width="50%"/></p> <p>선수의 타율에 대해 더 잘 알게 되었으므로, 이제 곡선이 더 얇아지고 오른쪽으로 이동했다(더 높은 타율).</p> <h2 id="compared-to-the-binomial-distribution">compared to the binomial distribution</h2> <p>binomial distribution, with $s$ success and $f$ failures out of a total of $(s+f)$ trials.</p> \[P(s, f \vert \theta) = \binom{s + f}{s} \theta^s (1 - \theta)^f \tag{2}\] <p>Thomson Sampling models uncertainty by building a probability distribution from historical rewards and then samples from the distribution when choosing actions. In the simple case where rewards are binary, a Beta distribution is used. The Beta distribution takes two parameters, α and β, and the mean value of the distribution is α/α + β which can be thought of as successes / successes + failures. To select an action, we sample from each arm’s Beta distribution and choose the arm with the highest sampled values.</p> <h2 id="usage-of-the-beta-distribution">Usage of the Beta Distribution</h2> <p>An example of Thompson Sampling is Doordash’s bandits for cuisine recommendations. User preferences for a cuisine is modeled via Beta(α=number of orders of the cuisine, β=number of orders of other cuisines). When selecting a set of cuisine filters to show on the explore page, the value for each cuisine is sampled from the cuisine’s Beta distribution. These values are then sorted in descending order to select the top cuisines to display.</p> <p>Doordash shared how they warm-start their cuisine bandits via higher-level regional data. For each cuisine, they learn a bandit policy at multiple levels (i.e., regional, subregional, user). The top-level bandit is initialized at Beta(α=1, β=1). Then, for each lower-level bandit, they update α by adding the average number of orders for the cuisine (at that level) and update β by adding the average number of orders for other cuisines (at that level). Finally, for the user-level bandit, α and β are updated with the user’s order data. As a result, a new user’s cuisine bandit is warm-started with higher-level marketplace data before each new order updates the bandit with their personal preferences.</p> <p>Reference: <a href="https://arxiv.org/abs/2009.06546">Carousel Personalization in Music Streaming Apps with Contextual Bandits</a></p> <hr/> <p>when feedback is delayed, Thompson Sampling outperforms UCB. Delayed feedback, where user-item interactions are not processed immediately, is common for most real-world systems due to resource and run-time constraints. In this situation, because UCB selects arms deterministically, it chooses the same action until new feedback is incorporated. In contrast, because Thompson Sampling chooses actions stochastically by sampling from the posterior distribution, it randomizes over actions even without updated rewards. Yahoo’s evaluation of Thompson Sampling and Deezer’s music bandit observed that this led to wider exploration and thus better outcomes.</p> <p>The initialization strategy is important.</p> <ul> <li>Naive initialization: the prior was Beta(1, 1).</li> <li>Pessimistic initialization: the prior was Beta(1, 99)</li> </ul> <p>That pessimistic initialization performed better due to the lower prior probabilities which were more reflective of real-world reward.</p> <h2 id="references">References</h2> <ul> <li><a href="https://en.wikipedia.org/wiki/Beta_distribution">Beta distribution (wikipedia)</a></li> <li><a href="https://applyingml.com/resources/bandits/">Bandits</a></li> <li><a href="https://stats.stackexchange.com/questions/47771/what-is-the-intuition-behind-beta-distribution/47782#47782">What is the intuition behind beta distribution?</a></li> </ul>]]></content><author><name></name></author><category term="ml-fundamentals"/><category term="machine-learning"/><category term="probability"/><category term="WIP"/><summary type="html"><![CDATA[확률 내용이긴 하지만, ML 에서도 자주 사용되는 beta distribution 에 대해서 정리해보자.]]></summary></entry><entry><title type="html">BGE 임베딩 학습 방법 탐방해보기</title><link href="https://zzong2006.github.io/blog/2025/bge-embed-train/" rel="alternate" type="text/html" title="BGE 임베딩 학습 방법 탐방해보기"/><published>2025-01-15T10:35:00+00:00</published><updated>2025-01-15T10:35:00+00:00</updated><id>https://zzong2006.github.io/blog/2025/bge-embed-train</id><content type="html" xml:base="https://zzong2006.github.io/blog/2025/bge-embed-train/"><![CDATA[<p>성능 좋은 한국어 임베딩 중에 <a href="https://huggingface.co/BAAI/bge-multilingual-gemma2">BAAI/bge-multilingual-gemma2</a> 가 있다.</p> <p>이 임베딩 모델을 커스텀 데이터셋으로 튜닝하고 싶은데 어떤식으로 진행하면 좋을지 확인해보자.</p> <p><a href="https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune/embedder#2-data-format">FlagEmbedding</a> 에서 파인튜닝을 위한 간단한 문서를 찾아볼 수 있다.</p> <h2 id="dataset">Dataset</h2> <p>학습 데이터셋은 <a href="https://huggingface.co/datasets/hanhainebula/bge-multilingual-gemma2-data/viewer/multilingual_miracl/ko_train">hanhainebula/bge-multilingual-gemma2-data</a> 에서 확인할 수 있다. 구분하기 쉽게 한국어 데이터셋 위주로 구성했다.</p> <p>query, pos, neg, pos_scores, neg_scores, prompt 로 구성되어 있다. pos 와 neg 는 각각 쿼리와 관련된 문서들과 관련이 없는 문서들을 의미한다. pos 와 neg 모두 여러개의 sentences 로 구성되어 있다.</p> <p>pos_scores 와 neg_scores 는 pos, neg 의 각 문서에 대한 점수를 의미하고, knowledge distillation 과정에서 사용되는 점수인것으로 보인다. 구체적인 방법은 찾아봐야 할것 같음 (TODO).</p> <p>prompt 는 retrieval 과정에서 query 와 함께 사용할 문장인것으로 보인다.</p> <h3 id="예시-샘플">예시 샘플</h3> <ul> <li>query : e스포츠란?</li> <li>pos: E스포츠\n일렉트로닉 스포츠(), 또는 간단히 줄여서 e스포츠()는 컴퓨터 통신이나 인터넷 따위를 통해서 온라인상으로 이루어지는 게임을 통틀어 이르는 말이다. (.. 생략 ..)</li> <li>neg: 국제 e스포츠 연맹\n국제e스포츠연맹은 2014년 7월부터 종목에 따라 남성부와 여성부로 분리하던 정책을 개정하여 여성도 남성부에 참가할 수 있도록 하였다.</li> <li>pos_scores: 90.75</li> <li>neg_scores: 89.81</li> <li>prompt: Given a question, retrieve Wikipedia passages that answer the question.</li> </ul> <h2 id="finetuning-process">Finetuning process</h2> <p>Negative mining -&gt; Teacher Scores (optional) -&gt; Data split -&gt; Finetuning 순으로 진행된다.</p> <h3 id="negative-mining">Negative Mining</h3> <p>임베딩 모델을 학습할 때 negative examples 은 매우 중요하다. 만약 특정 query 에 대해 negative text 가 없다면, 전체 corpus 에서 랜덤으로 샘플링해서 negative 로 사용할 수 있다.</p> <p>FlagEmbedding 에서 지원하는 negative examples 샘플링은 상당히 직관적인데 (<a href="https://github.com/FlagOpen/FlagEmbedding/blob/master/scripts/hn_mine.py">github code</a>), 다음과 같은 스텝을 거쳐서 뽑는다.</p> <ol> <li>query 와 corpus 를 준비한다.</li> <li>faiss 를 이용해서 index 를 구성하고, 각 query 마다 top-k 문서를 corpus 에서 뽑는다 (일반적으로 2 ~ 200).</li> <li>뽑은 문서들 중에서 쿼리와 positive 관계가 있는 문서들은 제외하고 나머지를 뽑아서 negative 로 사용한다. <ol> <li>negative 수준의 난이도를 낮추고 싶다면, top-k 를 더 낮추면 된다 (60 ~ 300).</li> </ol> </li> <li>만약 뽑은 negative 가 충분하지 않다면, 전체 corpus 에서 랜덤하게 뽑아서 채워준다.</li> </ol> <h3 id="teacher-scores">Teacher Scores</h3> <p>reranker 모델(e.g. <a href="https://huggingface.co/BAAI/bge-reranker-v2-m3">BAAI/bge-reranker-v2-m3</a>)을 이용해서 query 와 각 pos, neg 문서들의 점수를 계산한다.</p> <p>계산된 점수는 실제 학습에서 아래와 같이 loss 계산에 사용된다 (<a href="https://github.com/FlagOpen/FlagEmbedding/blob/b7efd286adbecff049949f3717b21a7b21c9d5ed/FlagEmbedding/abc/finetune/embedder/AbsModeling.py#L280-L318">코드 참고</a>).</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">distill_loss</span><span class="p">(</span><span class="n">kd_loss_type</span><span class="p">,</span> <span class="n">teacher_targets</span><span class="p">,</span> <span class="n">student_scores</span><span class="p">,</span> <span class="n">group_size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
  <span class="sh">"""</span><span class="s">
  teacher_targets: (batch_size, group_size) / (world_size * batch_size, group_size)
  student_scores: (batch_size, group_size) / (world_size * batch_size, group_size)
  </span><span class="sh">"""</span>

  <span class="k">return</span> <span class="o">-</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span>
      <span class="n">torch</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">log_softmax</span><span class="p">(</span><span class="n">student_scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">teacher_targets</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
  <span class="p">)</span>
</code></pre></div></div> <p>여기서 group_size 는 <code class="language-plaintext highlighter-rouge">group_size = p_reps.size(0) // q_reps.size(0)</code> 과 같이 한 query 가 처리할 수 있는 pessage 수를 의미하는데, 각 그룹당 local 의 개념을 가지고 있는것 같다.</p> <h3 id="data-split-by-length">Data split (by length)</h3> <p>학습할 데이터를 일정 길이 구간에 따라 나눈다: [0, 500], [500, 1000], [1000, 1500] …</p> <p>여기서 데이터 길이란 각 샘플 (query, pos, neg) 중 가장 긴 문장에 대한 길이를 의미한다.</p>]]></content><author><name></name></author><category term="code-review"/><category term="embedding"/><category term="RAG"/><category term="LLM"/><category term="finetuning"/><category term="WIP"/><summary type="html"><![CDATA[성능 좋은 한국어 임베딩 중에 BAAI/bge-multilingual-gemma2 가 있다.]]></summary></entry><entry><title type="html">ANN 방법론중 하나인 HNSW 알고리즘 정리</title><link href="https://zzong2006.github.io/blog/2025/hnsw/" rel="alternate" type="text/html" title="ANN 방법론중 하나인 HNSW 알고리즘 정리"/><published>2025-01-15T00:35:00+00:00</published><updated>2025-01-15T00:35:00+00:00</updated><id>https://zzong2006.github.io/blog/2025/hnsw</id><content type="html" xml:base="https://zzong2006.github.io/blog/2025/hnsw/"><![CDATA[<p>HNSW(Hierarchical Navigable Small World Graphs) 는 이름 그대로 계층적이지만 서로 이동 가능한, 여러 Small World를 만들어 그 안에서 근접 이웃을 탐색하는 방법이다.</p> <p>빠른 검색 결과 및 높은 정확도라는 장점을 제공하지만 메모리 사용량이 높은 단점이 있다.</p> <p>HNSW는 NSW에 skip list의 개념을 적용하여, NSW 그래프를 계층화한다. 가장 아래의 레이어는 모든 노드를 포함하며, 위로 갈수록 더 적은 노드로 구성된 형태의 그래프로 구성된다.</p> <h2 id="nsw-navigable-small-world-graphs">NSW (Navigable Small World Graphs)</h2> <p>우선 계층(Hierarchical)을 고려하기 전에 NSW(Navigable Small World Graphs) 를 먼저 생각해보자.</p> <p>NSW 에서는 검색 과정에서 임의로 선택된(또는 미리 정의된) 진입 노드(entry point)에서 시작하여 query 노드와 가까운 노드를 찾을때까지 진행하는데, 계속 찾는것은 아니고 일정 수준까지만 탐색을 수행한다.</p> <p><img src="https://i.imgur.com/6OcawHl.png" alt="Image" width="70%"/></p> <p>Small world 이론을 바탕으로, 적은 단계의 탐색만 거쳐도 충분히 쿼리와 근사한 노드를 반환할 수 있다는 가정이 깔려있다.</p> <p>이렇게 탐색의 정도를 제한하기 때문에, 데이터의 양이 많아져도 빠른 인덱싱 및 검색이 가능하다.</p> <h2 id="skip-list">Skip List</h2> <p>Skip list는 linked list 와 binary tree 자료 구조에 영감을 얻어서 만들어진 확률 기반 계층적(hierarchical) 자료 구조다.</p> <p>Skip list의 가장 하위 레벨의 층은 모든 데이터 노드를 포함하며, 상위 레벨의 층으로 갈수록 더 적은 수의 노드를 가진 linked list로 구성된다. 검색에 사용되는 링크는 다음 노드로 이어지는 기본 링크와 다른 레벨의 노드로 이어지는 링크로 구성된다.</p> <p>이러한 링크 구조는 전체 구조를 가로지르며 데이터를 빠르게 탐색할 수 있는 경로를 형성하는데, 검색, 삭제, 삽입 연산은 log 복잡도를 가진다.</p> <p><img src="https://i.imgur.com/hXuBvsR.gif" alt="Image" width="100%"/></p> <p>왜 확률적인 자료 구조로 불리는가? 그 이유는 새로운 노드를 삽입할때의 level 을 랜덤으로 정하기 때문이다.</p> <h2 id="hnsw">HNSW</h2> <p>HNSW는 skip list 구조를 채용하여 NSW 에 계층구조 형식을 추가한 것이다.</p> <p><img src="https://www.pinecone.io/_next/image/?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fvr8gru94%2Fproduction%2Fe63ca5c638bc3cd61cc1cd2ab33b101d82170426-1920x1080.png&amp;w=3840&amp;q=75" alt="Image" width="80%"/></p> <h3 id="search">Search</h3> <p>검색 과정에서는 가장 위쪽 레이어에 있는 노드부터 시작하는데, 일반적으로 진입 노드들은 더 높은 차수의 노드(=여러 레이어에 걸쳐 있는 링크를 가진 노드)로 설정하는 편이다.</p> <p>각 레이어에서 탐욕적으로 가장 가까운 정점으로 이동하여 local minimum(query 와 가장 가까운 노드) 을 찾는다. 그리고 이 시점에서 하위 레이어로 이동하여 다시 검색을 시작한다. 이 과정을 반복하여 최하위 레이어(레이어 0)의 로컬 최소값을 찾을 때까지 진행한다.</p> <p>이렇게 찾은 노드들은 최종적으로 쿼리와 가장 가까운 노드가 된다.</p> <h3 id="construction">Construction</h3> <p>그래프 구성도 상위 레이어에서 시작된다. 어떤 레이어에 주어진 노드를 넣을지는 특정 확률 값으로 결정되는데, 일반적으로 level 이 낮을수록 높은 확률을 가진다.</p> <p>처음 해야할일은 query 와 가장 가까운 (local minimum) <code class="language-plaintext highlighter-rouge">ef</code>(<code class="language-plaintext highlighter-rouge">efConstruction</code>)개의 노드를 찾는것이다. 그리고 하위 레이어로 내려가서 똑같은 과정을 반복하고, 랜덤으로 선택된 레벨에 도달할때까지 반복한다.</p> <p>이후 각 레이어에서 찾은 <code class="language-plaintext highlighter-rouge">ef</code>개의 노드들은 신규 노드에 대한 이웃으로 추가되는데, 다 추가되는것은 아니고 <code class="language-plaintext highlighter-rouge">M</code>개만 추가된다. 단순한 기준은 노드들의 거리가 가까운 순서대로 추가하는것이다.</p> <p>이렇게 정해진 레이어로 내려가면서 노드들을 추가하는 과정을 반복하여 타겟 노드에 이웃을 추가해주면 그래프 구성은 완료된다.</p> <h2 id="parameters">Parameters</h2> <p>HNSW의 벡터 인덱싱 및 검색에는 몇 가지 파라미터를 설정해주어야 하는데, 이러한 파라미터와 그 의미는 다음과 같다.</p> <ul> <li>$M$: 각 노드가 가질 수 있는 최대 이웃의 수를 나타낸다. $M$ 값이 높아지면 검색 정확도가 향상될 수 있지만, 그만큼 메모리 사용량과 인덱스 생성 시간이 증가한다.</li> <li>$\text{efConstruction}$: 인덱스를 생성할 때 탐색 크기를 의미한다. 이 값이 높을수록 더 깊고 정확한 탐색이 가능해져 인덱스 품질이 향상되지만, 인덱스 생성 시간이 길어질 수 있다.</li> <li>$\text{efSearch}$: 검색 시 탐색 크기를 의미한다. 이 값이 높을수록 더 깊고 정확한 탐색이 가능해져 검색 정확도가 향상되지만, **검색 시간이 늘어날 수 있다.</li> <li>$L_{max}$: 노드가 가질 수 있는 최대 레벨을 정의한다. 일반적으로 자동으로 설정되지만, 필요에 따라 사용자가 직접 지정할 수도 있다. $L_{max}$는 그래프의 계층적 구조와 깊이에 영향을 미친다.</li> </ul> <h2 id="references">References</h2> <ul> <li><a href="https://github.com/nmslib/nmslib">Non-Metric Space Library (nmslib)</a></li> <li><a href="https://jerry-ai.com/30">검색증강생성(RAG) - 그래프 기반 벡터 인덱스 HNSW(Hierarchical Navigable Small World)</a></li> <li><a href="https://ketansingh.me/posts/lets-talk-skiplist/">Let’s Talk SkipList</a></li> <li><a href="https://www.pinecone.io/learn/series/faiss/hnsw/">Pinecone: hNSW</a></li> </ul>]]></content><author><name></name></author><category term="search"/><category term="ANN"/><summary type="html"><![CDATA[HNSW(Hierarchical Navigable Small World Graphs) 는 이름 그대로 계층적이지만 서로 이동 가능한, 여러 Small World를 만들어 그 안에서 근접 이웃을 탐색하는 방법이다.]]></summary></entry><entry><title type="html">임베딩도 더 좋은 데이터가 필요하다, KaLM-Embedding</title><link href="https://zzong2006.github.io/blog/2025/kalm-embedding/" rel="alternate" type="text/html" title="임베딩도 더 좋은 데이터가 필요하다, KaLM-Embedding"/><published>2025-01-14T23:00:00+00:00</published><updated>2025-01-14T23:00:00+00:00</updated><id>https://zzong2006.github.io/blog/2025/kalm-embedding</id><content type="html" xml:base="https://zzong2006.github.io/blog/2025/kalm-embedding/"><![CDATA[<p>KaLM-Embedding이라는 multi-lingual 임베딩 모델을 소개한다. Qwen2-0.5B 기반 임베딩 모델에 좋은 데이터를 부어서 임베딩 성능을 높인 전략이다.</p> <h2 id="massive-dataset">Massive Dataset</h2> <p>기존의 유명한 임베딩 모델들과 비교했을때 fine-tuning 데이터 양의 비율을 크게 높인걸 확인할 수 있다.</p> <p><img src="https://i.imgur.com/DXEs65z.png" alt="Image" width="100%"/></p> <p>약 70개 이상의 학습 dataset 을 사용했으며, 대부분 중국어나 영어로 구성된 데이터로 구성되었다. 하지만 다국어 케이스에서도 성능이 좋았다고 함.</p> <h2 id="proposed-methods">Proposed Methods</h2> <p>더 많으면서 깨끗하고, 다양하고, 도메인 특화된 학습 데이터를 구하는 세가지 방법</p> <ol> <li>Diversity: LLM에서 추출한 다양한 예제를 생성하는 페르소나 기반 합성 데이터</li> <li>Quality: 덜 유익한 샘플을 제거하는 ranking consistency filtering</li> <li>Efficiency: 학습 효율성을 높이는 semi-homogeneous task batch</li> </ol> <h3 id="1-persona-based-synthetic-data">(1) Persona-based Synthetic Data</h3> <ul> <li>Qwen2-72B-Instruct를 사용하여 55만 개의 합성 데이터를 생성: 6 types of tasks with 40k unique instructions</li> <li>Persona Hub 에서 시스템 프롬프트를 랜덤으로 추출하여 domain diversity 를 높임</li> </ul> <h3 id="2-ranking-consistency-filtering">(2) Ranking Consistency Filtering</h3> <p><img src="https://i.imgur.com/EHjO00K.png" alt="Image" width="100%"/></p> <p>어떤 쿼리는 너무 광범위해서 모든 문서와 연관도가 높아서, 하나의 쿼리가 여러개의 문서에 positive case 로 고려될 수 있다. 이런 경우 hard negative mining 과정에서 noisy 한 데이터로 처리될 수 있다.</p> <p>이러한 문제를 해결하기 위해, query 와 corpus 의 유사도를 계산시, positive document 가 top-k 안에 들지 못한 경우 해당 데이터를 제거하는 방식을 취했다.</p> <h3 id="3-semi-homogeneous-task-batch">(3) Semi-homogeneous Task Batch</h3> <p><strong>최종 모델에 적용된 방법은 아니지만</strong>, 제안 느낌으로 소개되었다.</p> <p><img src="https://i.imgur.com/8daD7KG.png" alt="Image" width="70%"/></p> <p>동일한(homogeneous) task 내에서 negative sample 을 뽑으면 in-batch negative sample 에서 hardness 를 높이므로 성능에 좋은 영향을 줄 수 있지만, 동시에 대용량 데이터를 다룬다고 생각해보면 false negative 의 위험도 감수해야 한다.</p> <p>이러한 문제를 해결하기 위해, 각 task 에서 일정 비율로 샘플링을 진행하고 다른 배치로 할당하는 방식을 시도했다고 한다.</p> <p>아래는 semi-homogeneous ratio (다른 taks 끼리 얼마나 데이터를 섞을지 비율) 에 따른 MTEB 점수 결과이다.</p> <p><img src="https://i.imgur.com/SktSktk.png" alt="Image" width="50%"/></p> <p>보다시피 semi-homogeneous ratio 가 높으면 성능이 감소해서 최종 모델에는 채택이 되지 않았다 (근데 왜 논문에는 소개했을까..).</p> <h3 id="4-matryoshka-representation-learning-mrl">(4) Matryoshka Representation Learning (MRL)</h3> <p>이 외에도 Matryoshka Representation Learning 방식을 취해서 896, 512, 256, 128, and 64 차원에 대해서 loss weight 를 1.0, 0.3, 0.2, 0.1, and 0.1 로 설정하고 학습을 진행했다고 한다.</p> <p>아래 실험 결과에서도 차원수가 작으면 MRL 방식이 효과가 좋은것으로 보인다.</p> <p><img src="https://i.imgur.com/fkz5LZg.png" alt="Image" width="50%"/></p> <h2 id="ablation-study">Ablation Study</h2> <p><img src="https://i.imgur.com/5rYgKvt.png" alt="Image" width="70%"/></p> <p>가장 효과가 좋았던건 task instruction … 인데, 이건 임베딩 모델을 파인튜닝 할때 task 마다 instruction 을 다르게 주는 방식이다.</p> <p>아래는 그 예시 (역시 diversity 를 높이는 방식이 효과가 좋다).</p> <p><img src="https://i.imgur.com/7yQXsZj.png" alt="Image" width="100%"/></p> <p>그나저나 페르소나 데이터는 왜 ablation 결과에 없을까?</p> <h2 id="느낀점">느낀점</h2> <p>많은 시도를 해본것 같은데, 결국 다양한 데이터가 중요하다는걸 다시 느낀 report paper 였다.</p> <h2 id="references">References</h2> <ul> <li><a href="https://arxiv.org/pdf/2501.01028">KaLM-Embeddings: Superior Training Data Brings A Stronger Embedding Model</a></li> </ul>]]></content><author><name></name></author><category term="paper-review"/><category term="embedding"/><category term="RAG"/><category term="LLM"/><summary type="html"><![CDATA[KaLM-Embedding이라는 multi-lingual 임베딩 모델을 소개한다. Qwen2-0.5B 기반 임베딩 모델에 좋은 데이터를 부어서 임베딩 성능을 높인 전략이다.]]></summary></entry><entry><title type="html">ML Recap - Basic Feature Engineering</title><link href="https://zzong2006.github.io/blog/2025/basic-feature-engineering/" rel="alternate" type="text/html" title="ML Recap - Basic Feature Engineering"/><published>2025-01-12T23:00:00+00:00</published><updated>2025-01-12T23:00:00+00:00</updated><id>https://zzong2006.github.io/blog/2025/basic-feature-engineering</id><content type="html" xml:base="https://zzong2006.github.io/blog/2025/basic-feature-engineering/"><![CDATA[<p>numerical &amp; categorical 데이터에 대해서 간단한 전처리 기술을 복습해보자.</p> <h2 id="normalization">Normalization</h2> <p>…</p> <h2 id="one-hot-encoding">One-hot encoding</h2> <p>Categorical 데이터를 Numerical 데이터로 변환하는 방법이다. 즉, class 를 표현하기 위한 sparse binary vector 를 생성하는 것이다.</p> <h3 id="pros-and-cons">Pros and Cons</h3> <ul> <li>Pros: 단순하고 직관적이다.</li> <li>Cons: class 수가 많을경우 차원이 커져서 overfitting 이 발생할 수 있다. 그렇다고 너무 class 수를 제한하면 이 역시 underfitting 이 발생할 수 있다.</li> </ul> <h3 id="multicollinearity-방지-기법-dropping-first-class">multicollinearity 방지 기법: dropping first class</h3> <p>만약 선형 회귀 모델에 one-hot encoding 을 적용했을때, 다중공선성 이슈를 완화하기 위해 첫번째 카테고리를 제거하는 방법이 있다.</p> <p>예시를 통해 직관적으로 생각해보자. A, B, C 라는 세 개의 카테고리가 있을때 이를 one-hot encoding 하면 다음과 같은 행렬이 생성된다.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>A, B, C
[0, 1, 0]
[1, 0, 0]
[0, 0, 1]
</code></pre></div></div> <p>여기서 A와 B 가 0일때 C 는 확정적으로 1이다. 즉, A 와 B 의 값에 따라 C 의 값이 정해지는 것이므로 상관관계가 있다고 볼 수 있다.</p> <p>이때, 첫번째 카테고리를 제거하면 다음과 같은 행렬이 생성된다.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>B, C
[1, 0]
[0, 1]
[0, 0]
</code></pre></div></div> <p>여기서 [0, 0] 은 당연히 A에 해당된다고 유추가 가능하다.</p> <p>Correlation 이슈를 해결하기 위한 또 다른 방법은 PCA (Principal Component Analysis) 를 통해서 차원을 축소하는 방법이 있다.</p> <h2 id="other-encoding-methods">Other Encoding methods</h2> <h3 id="1-ordinal-encoding">(1) Ordinal encoding</h3> <p>범주형 데이터를 순서를 고려한 숫자로 변환하는 방법이다.</p> <p>예를 들어, 색상을 빨강, 노랑, 파랑으로 표현하면 1, 2, 3 으로 변환하는 것이다. 또는 어떤 구간을 나눠서 각 구간에 해당되는 클래스를 숫자로 변환하는 것도 가능하다.</p> <p>직관적인 방법이지만, 서로 관련없는 클래스도 하나의 숫자로 변환하는 것이 문제가 될 수 있어서 underfitting 이 발생할 수 있다.</p> <h3 id="2-target-encoding">(2) Target encoding</h3> <p>범주형 데이터를 대상 변수의 평균값으로 변환하는 방법이다. 범주형 데이터의 cardinality 가 높아서 one-hot encoding 을 적용하기 어려울 때 이 방법이 효과적이다. 주로 zip code 나 region 과 같은 feature 에 적용된다.</p> <p>예를 들어, 온라인 쇼핑몰에서 고객의 거주 지역에 따른 구매 금액을 예측하려고 한다고 가정해보자.</p> <table> <thead> <tr> <th>거주 지역</th> <th>구매 금액(타겟)</th> </tr> </thead> <tbody> <tr> <td>A</td> <td>100</td> </tr> <tr> <td>B</td> <td>150</td> </tr> <tr> <td>A</td> <td>200</td> </tr> <tr> <td>C</td> <td>300</td> </tr> <tr> <td>B</td> <td>100</td> </tr> <tr> <td>C</td> <td>400</td> </tr> </tbody> </table> <p>각 거주 지역에 대한 구매 금액의 평균을 계산하여 target encoding 을 수행할 수 있다.</p> <table> <thead> <tr> <th>거주 지역</th> <th>구매 금액 평균(인코딩 값)</th> </tr> </thead> <tbody> <tr> <td>A</td> <td>(100 + 200) / 2 = 150</td> </tr> <tr> <td>B</td> <td>(150 + 100) / 2 = 125</td> </tr> <tr> <td>C</td> <td>(300 + 400) / 2 = 350</td> </tr> </tbody> </table> <p>이런 방식은 orinal encoding 보다는 평균과 같은 통계적인 방식을 접목하므로, 좀 더 smooth 한 결과로 생각할 수 있다.</p> <h2 id="references">References</h2> <ul> <li><a href="https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-categorical-features">categorical-features (sklearn)</a></li> </ul>]]></content><author><name></name></author><category term="ml-fundamentals"/><category term="machine-learning"/><category term="feature-engineering"/><category term="pre-processing"/><category term="WIP"/><summary type="html"><![CDATA[numerical &amp; categorical 데이터에 대해서 간단한 전처리 기술을 복습해보자.]]></summary></entry><entry><title type="html">ML Recap - Linear Regression</title><link href="https://zzong2006.github.io/blog/2025/linear-regression/" rel="alternate" type="text/html" title="ML Recap - Linear Regression"/><published>2025-01-12T21:00:00+00:00</published><updated>2025-01-12T21:00:00+00:00</updated><id>https://zzong2006.github.io/blog/2025/linear-regression</id><content type="html" xml:base="https://zzong2006.github.io/blog/2025/linear-regression/"><![CDATA[<h2 id="lasso-regression">Lasso Regression</h2> <p>Lasso 는 L1 정규화(Regularization) 라고 불리는 sparse 한 선형 회귀 모델이다.</p> <p>이 모델의 특징으로는 variable selection 과 regularization 을 통해 모델의 예측 정확도와 interpretability 을 향상시키는 것이다.</p> <p>아래는 regression 의 cost function $J(\mathbf{w})$ 이다. 이 함수를 최소화 하는 계수 $\mathbf{w}$ 를 찾는 것이 목적이다.</p> \[J(\mathbf{w})=\frac{1}{N} \sum_{i=1}^N\left(y_i-\mathbf{w}^T \mathbf{x}_i\right)^2+\lambda \sum_{j=1}^m\left|w_j\right|\] <p>regression parameter $\lambda$ 는 성능에 큰 영향을 미친다. 아래 그림과 같이 $\lambda$ 가 커질수록 모델의 bias 가 커지며, 반대로 모델의 variance 는 작아진다.</p> <p><img src="https://i.imgur.com/wYVpKQH.png" alt="20250112223049" width="85%"/></p> <h3 id="limitation">Limitation</h3> <p>Lasso 는 독립 변수들 간에 강한 상관관계가 존재하는 현상인 다중공선성(multicollinearity) 문제를 해결하기엔 한계가 있다. 왜냐하면 lasso 는 다중공선성에 관련된 변수들 중 임의로 하나만 살려두기 때문에, 모델 해석에 어려움을 줄 수 있기 때문이다 (동시에 성능 하락은 덤).</p> <h2 id="ridge-regression">Ridge Regression</h2> <p>Ridge regression 은 과적합을 방지하기 위해 회귀 계수(coefficient)의 제곱의 합을 작게 만들어 준다. 하지만, 이 방식은 변수 선택을 하지 않기 때문에 모델을 해석하는데 어려움이 있다.</p> <p>반대로 Lasso 는 회귀 계수의 절대값의 합을 작게 만들어 준다. 이 방식은 특정 계수를 0으로 만들어서 예측에 영향을 가지 않도록 만들기 때문에 변수 선택 과정에서 이점이 있다.</p> <p>아래는 Lasso 와 Ridge 모델이 두개의 parameter $\beta_1$ 과 $\beta_2$ 로 표현될때, 각 방식 별 가능한한 parameter 의 조합을 나타낸 그래프이다.</p> <p><img src="https://i.imgur.com/vDcn664.png" alt="20250112221358" width="80%"/></p> <h3 id="as-classification">As classification</h3> <p>Ridge 방식은 regression 뿐만 아니라 분류 task 를 해결하는데도 자주 사용되는데, 종종 Logistic Regression 보다 선호되는 경우가 많다. 왜냐하면 계수를 찾기위해서는 아래와 같이 projection matrix 를 한번만 계산하면 되기 때문이다.</p> \[\hat{\beta}_{\text {ridge }}=\left(X^T X+\lambda I\right)^{-1} X^T y\] <p>그래서 계산 효율적인 특성이 있으며 대규모 데이터셋을 처리할때 자주 사용된다. 또한 accuracy 나 recall 에서도 SVM 이나 Logistic Regression 대비해서 유사한 결과를 얻는 사례가 많다.</p> <h2 id="elasticnet">ElasticNet</h2> <p>ElasticNet 은 선형 회귀 모델에서 L1 regularization (Lasso) 과 L2 regularization (Ridge) 를 결합한 정규화 기법이다. 이 모델은 계수의 절대값의 합과 제곱의 합을 작게 만들어 준다.</p> \[J(\mathbf{w})=\frac{1}{N} \sum_{i=1}^N\left(y_i-\mathbf{w}^T \mathbf{x}_i\right)^2+\alpha\left(r \sum_{i=1}^n\left|\mathbf{w}_i\right|+\left(1-r\right) \sum_{i=1}^n \mathbf{w}_i^2\right)\] <ul> <li>$\alpha$ 는 regularization 의 강도를 조절하는 매개변수이다.</li> <li>$r$ 은 L1 과 L2 의 비율을 조절하는 매개변수이다 (0 &lt; $r$ &lt; 1). $r$ 이 0 에 가까울수록 L2 정규화가 강해지고, 1 에 가까울수록 L1 정규화가 강해진다.</li> </ul> <p>ElasticNet 은 상관관계가 높은 변수들이 함께 선택되거나 제외되는 그룹화 효과(grouping effect)를 보인다. 그래서 ElasticNet은 여러 특성(feature)들이 서로 상관관계가 있을 때 유용하다. Lasso는 이러한 특성들 중 하나를 무작위로 선택하는 경향이 있는 반면, ElasticNet은 이들 모두를 선택하는 경향이 있다.</p> <h3 id="limitation-1">Limitation</h3> <p>L1 과 L2 비율을 조절하는 과정이 필요하므로, 기존의 lasso 나 ridige 보다 튜닝이 복잡해지거나 계산 비용이 증가할 수 있다. 또한 L1 방식과 달리 모델의 해석이 좀 더 복잡해지는 것도 단점으로 생각할 수 있다.</p> <h2 id="skicit-learn-을-통한-구현">skicit-learn 을 통한 구현</h2> <p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html">LassoCV</a> 는 cross-validation 을 통해 최적의 $\alpha$ 를 찾아서 회귀 모델을 튜닝해준다. 여기서는 regularization parameter $\alpha$ 로 표현한다.</p> <p>이 외에도 LogisticRegressionCV, ElasticNetCV 도 있다.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="kn">from</span> <span class="n">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nf">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">linear_model</span><span class="p">.</span><span class="nc">LassoCV</span><span class="p">(</span><span class="n">alphas</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">13</span><span class="p">),</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">reg</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">reg</span><span class="p">.</span><span class="n">alpha_</span>
</code></pre></div></div> <p>위 코드는 아래 그래프처럼 여러 fold 에 대한 MSE 를 계산하고, 가능한 alpha 값들 중 최적의 alpha 값을 찾아준다.</p> <p><img src="https://i.imgur.com/IPGrB1d.png" alt="20250112225530" width="60%"/></p> <h2 id="references">References</h2> <ul> <li><a href="https://en.wikipedia.org/wiki/Lasso_(statistics)">Lasso Regression (wikipedia)</a></li> <li><a href="https://scikit-learn.org/stable/modules/linear_model.html#using-cross-validation">Using cross-validation (sklearn)</a></li> </ul>]]></content><author><name></name></author><category term="ml-fundamentals"/><category term="machine-learning"/><category term="linear-regression"/><summary type="html"><![CDATA[Lasso Regression]]></summary></entry><entry><title type="html">Embedding 과 Reranker 은 무슨 차이일까?</title><link href="https://zzong2006.github.io/blog/2025/embed-and-rerank/" rel="alternate" type="text/html" title="Embedding 과 Reranker 은 무슨 차이일까?"/><published>2025-01-12T10:00:00+00:00</published><updated>2025-01-12T10:00:00+00:00</updated><id>https://zzong2006.github.io/blog/2025/embed-and-rerank</id><content type="html" xml:base="https://zzong2006.github.io/blog/2025/embed-and-rerank/"><![CDATA[<p>임베딩과 리랭킹 모델은 어떤 차이가 있는지 궁금해서 찾아봤다.</p> <h2 id="embedding">Embedding</h2> <p>임베딩 모델은 말 그대로 text 를 임베딩으로 변환하는 모델이다.</p> <p>query 와 passage 를 입력으로 받아서, 임베딩 모델은 각 임베딩을 출력하고, 유사도 계산으로 두 임베딩을 활용할 수 있다.</p> <h2 id="reranker">Reranker</h2> <p>리랭킹 모델은 임베딩 모델과 다르게 입력으로 question 과 document 를 입력으로 받아서, 직접적으로 유사도를 계산하는 방식이다. 즉, 임베딩을 생성하지 않고, relevance score 를 계산한다.</p> <p>score 는 일반적으로 sigmoid 함수를 통해서 [0,1] 사이의 float 값으로 변환된다.</p> <h2 id="reference">Reference</h2> <p>Reranker</p> <ul> <li><a href="https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/inference/reranker">FlagEmbedding - reranker</a></li> <li><a href="https://huggingface.co/BAAI/bge-reranker-base">BAAI/bge-reranker-base</a></li> </ul>]]></content><author><name></name></author><category term="miscellaneous"/><category term="Retrieval"/><category term="RAG"/><summary type="html"><![CDATA[임베딩과 리랭킹 모델은 어떤 차이가 있는지 궁금해서 찾아봤다.]]></summary></entry><entry><title type="html">kaggle 의 multilingual-chatbot-arena 대회</title><link href="https://zzong2006.github.io/blog/2025/kaggle-wsdm-cup/" rel="alternate" type="text/html" title="kaggle 의 multilingual-chatbot-arena 대회"/><published>2025-01-12T10:00:00+00:00</published><updated>2025-01-12T10:00:00+00:00</updated><id>https://zzong2006.github.io/blog/2025/kaggle-wsdm-cup</id><content type="html" xml:base="https://zzong2006.github.io/blog/2025/kaggle-wsdm-cup/"><![CDATA[<p>kaggle 에서 진행되는 <a href="https://www.kaggle.com/competitions/wsdm-cup-multilingual-chatbot-arena/">WSDM Cup Multilingual Chatbot Arena</a> 대회가 있다.</p> <p>대회는 모델 a 와 b 의 응답이 주어졌을때 어떤 응답이 더 좋은지 판단하는 모델을 만드는 대회이다.</p> <p>현재 2025년 01월 12일 기준으로 상위권 리더보드 점수는 accuracy 기준으로 대략 0.700 ~ 0.708 사이의 점수를 기록하고 있다.</p> <p><a href="https://www.kaggle.com/competitions/wsdm-cup-multilingual-chatbot-arena/discussion/552368">Dicussion 에 작성된 상위권 방식</a>을 참고해보니 아래와 같다.</p> <ul> <li>모델은 Gemma2-9b-it (bf16): fp16 을 사용했더니 정확도가 감소했다고 함.</li> <li>Cross validation 을 통해 학습하며, fold 는 5개 (fold 0 에서 가장 좋은 성적을 보이는듯 함)</li> <li>길이(max_length) 는 2048 보다는 3072 가 더 좋은 스코어를 보여주는 것으로 보임</li> <li>TTA 를 수행하는 경우 accuracy 가 꽤 올라가는 모습을 보인다</li> </ul> <p>그 외에도 inference 를 빠르게 하는것이 핵심인것으로 보인다.</p> <h2 id="other-notebooks-탐방">Other notebooks 탐방</h2> <ul> <li><a href="https://www.kaggle.com/code/artemgoncarov/multilingual-chatbot-arena-challenge-baseline/notebook">LGBM 기반 분류모델: 0.612 정도의 점수를 기록</a>이다.</li> </ul>]]></content><author><name></name></author><category term="competition"/><category term="kaggle"/><category term="LLM"/><summary type="html"><![CDATA[kaggle 에서 진행되는 WSDM Cup Multilingual Chatbot Arena 대회가 있다.]]></summary></entry><entry><title type="html">LLM 기반 Dense Retrieval 을 위한 학습방법, LLaRA</title><link href="https://zzong2006.github.io/blog/2025/use-llm-for-dense-retrieval/" rel="alternate" type="text/html" title="LLM 기반 Dense Retrieval 을 위한 학습방법, LLaRA"/><published>2025-01-11T16:00:00+00:00</published><updated>2025-01-11T16:00:00+00:00</updated><id>https://zzong2006.github.io/blog/2025/use-llm-for-dense-retrieval</id><content type="html" xml:base="https://zzong2006.github.io/blog/2025/use-llm-for-dense-retrieval/"><![CDATA[<h2 id="llm-vs-dense-retrieval">LLM vs. Dense Retrieval</h2> <p>BERT 와 같은 모델이 아닌 decoder-only LLM 으로 구성된 모델에서 임베딩을 추출하면 뭐가 문제일까?</p> <ul> <li>LLM 은 텍스트 생성 작업을 위해 학습되었기 때문에, 토큰 예측을 위한 임베딩을 학습하게 된다. 이 때문에 임베딩은 주로 주변 토큰과 미래 토큰에 집중된다.</li> <li>반면, dense retrieval 은 전체 문맥에 대한 전역적인 의미를 표현하는 임베딩을 필요로 한다.</li> </ul> <p>이러한 차이는 LLM 을 dense retrieval 에 직접 적용하는 것을 제한한다.</p> <h3 id="methodology">Methodology</h3> <p>다음과 같이 토크나이징된 입력 시퀀스 $T: [CLS], t_1, …, t_N, [EOS]$ 가 주어졌다고 가정하자.</p> <p>BERT 에서는 다음 두가지 방법으로 임베딩을 추출하는 것이 일반적이다.</p> <ul> <li>$e_t ← \text{BERT}(T)[CLS]$</li> <li>$e_t ← \text{AVG}(\text{BERT}(T))$: mean pooling</li> </ul> <p>하지만 LLM 에서 임베딩을 추출하려면, 제일 마지막 토큰인 <code class="language-plaintext highlighter-rouge">&lt;/s&gt;</code> 또는 $\text{[EOS]}$ 를 사용한다. 예를 들어, LLaMA 에서는 다음과 같이 임베딩을 추출한다.</p> <p>$e_t ← \text{LLaMA}(T)[⟨\text{EOS}⟩]$</p> <p>하지만 LLM 에서의 임베딩은 전체 문맥이 아니라 local 과 near-future semantic 에 집중되어 있기 때문에, 전체 문맥을 표현하는 임베딩을 추출하는 것이 어렵다.</p> <h2 id="llara">LLaRA</h2> <p>위와 같은 LLM 의 한계를 극복하고 dense retrieval 에 적용하기 위해서 LLaRA 라는 방법을 제안한다. LLaRA 는 일종의 비지도 생성형 pretraining 이라고 볼 수 있으며, 두 전처리 훈련 작업에 기반한다.</p> <p><img src="https://i.imgur.com/uUtuEIw.png" alt="LLaRA" width="100%"/></p> <ol> <li>EBAE (Embedding-Based Auto-Encoding): LLM 이 입력 문장을 구성하는 토큰들을 예측할 수 있도록 하는 훈련. 주로 similarity search 에 사용된다.</li> <li>EBAR (Embedding-Based Auto-Regression): EBAE 와 유사하지만, 입력 문장의 다음 문장(next sentence)을 예측할 수 있도록 하는 훈련. 주로 question answering 에 사용된다.</li> </ol> <p>LLaRA 에서는 sentence-level features 을 예측하는 것은 LLM 의 linear projection 을 통해 이루어지고, 추가적인 decoding process 는 필요하지 않다. 즉, 기존의 pretrained model 에 대해 LLaRA 를 적용하는 것이 가능하므로, 효율적인 접근 방법이라고 할 수 있다.</p> <h3 id="prediction--training">Prediction &amp; Training</h3> <p>EBAE 와 EBAR 은 다음과 같이 동시에 예측 및 훈련된다.</p> <p><strong>Inference</strong></p> <p>Prompt 는 어떤 sequence $T$ 와 SELF 문장 (<code class="language-plaintext highlighter-rouge">The original sentence:</code>), <code class="language-plaintext highlighter-rouge">&lt;\s&gt;</code> 그리고 NEXT 문장 (<code class="language-plaintext highlighter-rouge">The next sentence:</code>), <code class="language-plaintext highlighter-rouge">&lt;\s&gt;</code> 를 사용한다. 여기서 T 는 학습할 시퀀스를 의미하고, SELF 는 원본 문장에 대한 임베딩, 그리고 NEXT 는 원본 문장에 대한 다음 문장의 임베딩을 의미한다. 즉, 프롬프트로 구성하면 <code class="language-plaintext highlighter-rouge">T The original sentence: &lt;\s&gt; The next sentence: &lt;\s&gt;</code> 으로 구성하고 이걸 LLM 에 밀어넣어서 각 <code class="language-plaintext highlighter-rouge">&lt;\s&gt;</code> 에 대한 임베딩을 추출하면 EBAE 와 EBAR 의 값을 얻을 수 있는것이다.</p> <p>근데 이렇게 하면 SELF 문장이 NEXT 문장에 영향을 줄 수 있으므로, 아래 그림처럼 attention mask 를 수정해서 이를 방지한다.</p> <p><img src="https://i.imgur.com/wqPpY48.png" alt="Image" width="50%"/></p> <p>여기서 보면 NEXT 문장에 대해 예측할때 SELF 문장에 대한 정보를 볼 수 없도록 masking 하는 것을 확인할 수 있다.</p> <p><strong>Training</strong></p> <p>위 EBAE 와 EBAR 의 예측 과정을 통해 얻은 임베딩을 $e_t$ 라고 하면, linear projection matrix $W ∈ R^{\text{vocab_size}×d}$ 을 적용하고, original 문장에 대한 토큰들 (for EBAE) 과 다음 문장에 대한 토큰들 (for EBAR) 에 대한 확률 값을 최대화하는 것을 목표로 학습을 진행한다.</p> <p><a href="https://github.com/FlagOpen/FlagEmbedding/blob/808b6c8cc9b36e02278bd572909cf13d10d78598/research/LLARA/pretrain/modeling.py#L314-L388">Loss 를 계산하는 모델 forward 코드</a>를 찾았긴 했는데 논문에 나와있는 내용과 꽤 다른것 같다.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Logit 계산 부분
</span><span class="n">outputs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">(...)</span>
<span class="n">hidden_states</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">pretraining_tp</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">lm_head_slices</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">lm_head</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">vocab_size</span> <span class="o">//</span> <span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">pretraining_tp</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="p">[</span><span class="n">F</span><span class="p">.</span><span class="nf">linear</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">,</span> <span class="n">lm_head_slices</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">pretraining_tp</span><span class="p">)]</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">lm_head</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">.</span><span class="nf">float</span><span class="p">()</span>

<span class="c1"># AR Loss 계산 부분 (AR 은 EBAR 인건지?)
</span><span class="n">ar_loss</span> <span class="o">=</span> <span class="bp">None</span>
<span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
    <span class="c1"># Shift so that tokens &lt; n predict n
</span>    <span class="n">shift_logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[...,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:].</span><span class="nf">contiguous</span><span class="p">()</span>
    <span class="n">shift_labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[...,</span> <span class="mi">1</span><span class="p">:].</span><span class="nf">contiguous</span><span class="p">()</span>
    <span class="c1"># Flatten the tokens
</span>    <span class="n">loss_fct</span> <span class="o">=</span> <span class="nc">CrossEntropyLoss</span><span class="p">()</span>
    <span class="n">shift_logits</span> <span class="o">=</span> <span class="n">shift_logits</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">vocab_size</span><span class="p">)</span>
    <span class="n">shift_labels</span> <span class="o">=</span> <span class="n">shift_labels</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># Enable model parallelism
</span>    <span class="n">shift_labels</span> <span class="o">=</span> <span class="n">shift_labels</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">shift_logits</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">ar_loss</span> <span class="o">=</span> <span class="nf">loss_fct</span><span class="p">(</span><span class="n">shift_logits</span><span class="p">,</span> <span class="n">shift_labels</span><span class="p">)</span>
</code></pre></div></div> <h2 id="실험-결과">실험 결과</h2> <p>LLaMA 2-7B 을 base 모델로 삼았으며, unlabeled 위키피디아 데이터를 학습에 사용했다고 한다. 또한, LoRA 를 이용해서 먼저 학습 후 ANN hard negative sampling 을 통해 추가적인 학습(contrastive learning)을 진행했다고 한다.</p> <p>BEIR 벤치마크에서 LLaRA 는 56.1 (NDCG@10), BERT 는 40.1, BM25 는 43.7 점을 달성했다. 참고로 openai 의 ada-2 모델은 52.1 점을 달성했다.</p> <h2 id="느낀점">느낀점</h2> <ul> <li>뭔가 정리가 잘 안된 논문같다. 코드도 좀 복잡해서 이해하기 어려웠다.</li> <li>EBAR 과 EBAE 내용을 쭉 설명하다가 갑자기 실험에는 ANN 을 사용해서 contrastive learning 을 진행했다고 하는데 갑툭튀 느낌이라 당황스러웠다. 코드를 살펴보니 pretrained 과정과 finetuning 과정이 따로 있어서 그런듯 해보였음.</li> </ul> <h2 id="reference">Reference</h2> <p>paper</p> <ul> <li><a href="https://arxiv.org/pdf/2312.15503">Making Large Language Models A Better Foundation For Dense Retrieval</a></li> <li><a href="https://arxiv.org/abs/2007.00808">Approximate nearest neighbor negative contrastive learning for dense text retrieval</a>: 실험 진행할 때 사용한 방법</li> </ul> <p>Others</p> <ul> <li><a href="https://huggingface.co/BAAI/bge-reranker-v2-gemma">BAAI/bge-reranker-v2-gemma (huggingface model)</a></li> <li><a href="https://github.com/FlagOpen/FlagEmbedding/tree/master/research/LLARA">FlagEmbedding (github)</a>: 구현 코드</li> </ul>]]></content><author><name></name></author><category term="paper-review"/><category term="LLM"/><category term="dense_retrieval"/><summary type="html"><![CDATA[LLM vs. Dense Retrieval]]></summary></entry><entry><title type="html">Algorithm lesson learned - string</title><link href="https://zzong2006.github.io/blog/2025/algorithm-lesson-learned-string/" rel="alternate" type="text/html" title="Algorithm lesson learned - string"/><published>2025-01-11T10:00:00+00:00</published><updated>2025-01-11T10:00:00+00:00</updated><id>https://zzong2006.github.io/blog/2025/algorithm-lesson-learned-string</id><content type="html" xml:base="https://zzong2006.github.io/blog/2025/algorithm-lesson-learned-string/"><![CDATA[<p>알고리즘 string 관련 문제를 풀면서 인사이트를 얻은 내용들을 정리합니다.</p> <h2 id="palindromes-회문">Palindromes (회문)</h2> <p>Palindrome 의 특성</p> <ul> <li>회문은 반드시 홀수 번 등장하는 문자가 중심이 되어야 한다. 예를 들어, “aba” 와 같이 “b” 는 홀수번 등장한다 (또는 “abbba”, “abxba”).</li> <li>그래서 주어진 문자들로 회문을 만든다고 하면, 홀수 번 등장하는 문자의 개수가 회문의 개수를 결정한다.</li> </ul> <h3 id="related-problem">Related problem</h3> <ul> <li><a href="https://leetcode.com/problems/construct-k-palindrome-strings/description/?envType=daily-question&amp;envId=2025-01-11">leetcode: construct-k-palindrome-strings</a></li> </ul>]]></content><author><name></name></author><category term="algorithm"/><category term="competitive-programming"/><category term="string"/><category term="lesson-learned"/><summary type="html"><![CDATA[알고리즘 string 관련 문제를 풀면서 인사이트를 얻은 내용들을 정리합니다.]]></summary></entry></feed>